{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:white;\" >\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"float: left; width: 14%; padding: 5px; height:auto\">\n",
    "    <img src=\"img/TUBraunschweig_CO_200vH_300dpi.jpg\" alt=\"TU_Braunschweig\" style=\"width:100%\">\n",
    "  </div>\n",
    "  <div style=\"float: left; width: 28%; padding: 5px; height:auto\">\n",
    "    <img src=\"img/TU_Clausthal_Logo.png\" alt=\"TU_Clausthal\" style=\"width:100%\">\n",
    "  </div>\n",
    "  <div style=\"float: left; width: 25%; padding: 5px; height:auto\">\n",
    "    <img src=\"img/ostfalia.jpg\" alt=\"Ostfalia\" style=\"width:100%\">\n",
    "  </div>\n",
    "  <div style=\"float: left; width: 21%; padding: 5px;\">\n",
    "    <img src=\"img/niedersachsen_rgb_whitebg.png\" alt=\"Niedersachsen\" style=\"width:100%\">\n",
    "  </div>\n",
    "  <div style=\"float: left; width: 9%; padding: 5px;\">\n",
    "    <img src=\"img/internet_BMBF_gefoerdert_2017_en.jpg\" alt=\"bmbf\" style=\"width:100%\">\n",
    "  </div>\n",
    "</div>\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"img/ki4all.jpg\" alt=\"KI4ALL-Logo\" width=\"200\"/>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Synthetic Biomedical Data – Lesson 2a: Data Generation Basics (Part 1)\n",
    "\n",
    "Part of the *Microcredit Artificial Data Generator* learning module.\n",
    "\n",
    "➡️ [Back to Lesson 1: Introduction](01_intro.ipynb)\n",
    "➡️ [Module Overview (README)](../README.md)\n",
    "\n",
    "*Before continuing, please make sure you have reviewed the **prerequisites** and **learning goals** in Lesson 1.*"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Recap from Lesson 1\n",
    "- Synthetic biomedical data is artificially generated but mimics statistical properties of real datasets.\n",
    "- It allows us to know the *ground truth* (feature importance, class distributions).\n",
    "- Useful for benchmarking, teaching, privacy-preserving research.\n",
    "\n",
    "In Lesson 1, you learned why synthetic biomedical data is useful.\n",
    "Now we create and explore our **first simple dataset**.\n",
    "\n",
    "## Learning Goals (Lesson 2)\n",
    "\n",
    "The goal of this lesson is to give you hands-on experience with creating small, controlled datasets that demonstrate the key concepts of synthetic biomedical data.\n",
    "Later notebooks will expand this by introducing **pseudo-classes**, **random effects**, and more advanced data structures.\n",
    "\n",
    "After completing this lesson, you will be able to:\n",
    "\n",
    "1. **Generate** a simple synthetic biomedical dataset with controlled numbers of samples, features, and classes.\n",
    "2. **Inspect** the structure of the dataset (features, labels, class balance) in a Pandas DataFrame.\n",
    "3. **Visualize** data using scatterplots and histograms to explore class separability.\n",
    "4. **Identify** which features appear informative and which behave like noise.\n",
    "5. **Quantify** the strength of class separation using effect size measures (Cohen’s d, Cliff’s delta), and relate these values to visual impressions.\n",
    "6. **Explain** why synthetic data provides a safe playground for learning and method testing before moving on to more complex cases.\n",
    "---\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Lesson 2a: Data Generation Basics — First Dataset\n",
    "\n",
    "In this notebook, we will move from theory to practice and learn how to **generate synthetic biomedical datasets** using Python.\n",
    "You will see how simple tools (e.g., `scikit-learn`) can be used to create datasets that mimic the structure of real biomedical data while allowing full control over:\n",
    "\n",
    "- **Number of samples** (patients, experiments, or observations)\n",
    "- **Number of features** (biomarkers or measurements)\n",
    "- **Number of classes** (e.g., healthy vs. diseased groups)\n",
    "- **Feature importance** (which features carry useful information)\n",
    "- **Noise and irrelevant features** (variables that add randomness or distraction)\n",
    "\n",
    "###  Learning Goals\n",
    "After completing this notebook, you will be able to:\n",
    "1. Generate a synthetic dataset with `make_classification`.\n",
    "2. Inspect the structure of the dataset (samples, features, labels).\n",
    "3. Check the class distribution.\n",
    "4. Visualize class separability with a simple scatterplot.\n",
    "\n",
    "---"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Lesson 2a.1 — Generate a simple synthetic dataset\n",
    "\n",
    "We will create a tiny synthetic dataset that imitates biomedical measurements:\n",
    "- **Samples** ≈ patients\n",
    "- **Features** ≈ biomarkers (e.g., gene expression levels)\n",
    "- **Class** ≈ outcome (e.g., healthy vs. diseased)\n",
    "\n",
    "This minimal example uses `sklearn.datasets.make_classification`, which lets us control:\n",
    "- number of samples and features,\n",
    "- how many features are truly informative,\n",
    "- the number of classes.\n",
    "\n",
    "> **Goal:** Get a quick, tangible dataset to explore (as a Pandas DataFrame).\n"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T11:00:26.241289Z",
     "start_time": "2025-08-29T11:00:25.774167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Lesson 2a: First Example – Generate a simple synthetic dataset\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "\n",
    "# Generate a dataset with:\n",
    "# - 30 samples (rows, like patients)\n",
    "# - 8 features (columns, like biomarkers)\n",
    "# - 2 informative features (really matter for classification)\n",
    "# - 2 classes (e.g., healthy vs diseased)\n",
    "X, y = make_classification(\n",
    "    n_samples=30,\n",
    "    n_features=8,\n",
    "    n_informative=2,\n",
    "    n_redundant=0,\n",
    "    n_classes=2,\n",
    "    class_sep=1.0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Put into a DataFrame for easier handling\n",
    "feature_names = [f\"feature_{i+1}\" for i in range(X.shape[1])]\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df[\"class\"] = y\n",
    "\n",
    "# Show first rows\n",
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   2.122156   0.917862   1.223877  -1.260884  -1.519370   1.032465   \n",
       "1   0.570891   3.852731   1.749427   0.515048   0.954002   1.135566   \n",
       "2   0.257550   0.174578  -0.667208   1.886186  -1.918771  -0.074446   \n",
       "3   0.296120  -1.463515  -1.824213  -0.392108   0.005113   0.261055   \n",
       "4  -0.990536   2.190456  -1.221743   0.586857   0.099651  -0.566298   \n",
       "\n",
       "   feature_7  feature_8  class  \n",
       "0  -0.484234   0.854515      1  \n",
       "1   0.651391  -1.718794      0  \n",
       "2  -0.026514  -0.432656      0  \n",
       "3  -0.234587  -2.646789      0  \n",
       "4  -0.503476   0.703892      1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.122156</td>\n",
       "      <td>0.917862</td>\n",
       "      <td>1.223877</td>\n",
       "      <td>-1.260884</td>\n",
       "      <td>-1.519370</td>\n",
       "      <td>1.032465</td>\n",
       "      <td>-0.484234</td>\n",
       "      <td>0.854515</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.570891</td>\n",
       "      <td>3.852731</td>\n",
       "      <td>1.749427</td>\n",
       "      <td>0.515048</td>\n",
       "      <td>0.954002</td>\n",
       "      <td>1.135566</td>\n",
       "      <td>0.651391</td>\n",
       "      <td>-1.718794</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.257550</td>\n",
       "      <td>0.174578</td>\n",
       "      <td>-0.667208</td>\n",
       "      <td>1.886186</td>\n",
       "      <td>-1.918771</td>\n",
       "      <td>-0.074446</td>\n",
       "      <td>-0.026514</td>\n",
       "      <td>-0.432656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.296120</td>\n",
       "      <td>-1.463515</td>\n",
       "      <td>-1.824213</td>\n",
       "      <td>-0.392108</td>\n",
       "      <td>0.005113</td>\n",
       "      <td>0.261055</td>\n",
       "      <td>-0.234587</td>\n",
       "      <td>-2.646789</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.990536</td>\n",
       "      <td>2.190456</td>\n",
       "      <td>-1.221743</td>\n",
       "      <td>0.586857</td>\n",
       "      <td>0.099651</td>\n",
       "      <td>-0.566298</td>\n",
       "      <td>-0.503476</td>\n",
       "      <td>0.703892</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Interpretation & Takeaways\n",
    "- Each **row** is a sample (patient); each **feature_*** column is a biomarker.\n",
    "- The **class** column is our target (0/1). At this point, the numbers are just synthetic values—what matters is the structure.\n",
    "- We specified **2 informative features**; the others may behave like noise here.\n",
    "\n",
    "**Reflection**\n",
    "- How would changing `n_informative` or `n_features` affect downstream plots and model difficulty?\n",
    "- What happens if you increase `n_samples` to 1000?\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2a.2 Explore Class Distribution\n",
    "\n",
    "Before diving deeper into feature analysis, it is important to understand how many samples\n",
    "belong to each class (e.g., **healthy** vs. **diseased**). This is called the **class distribution**.\n",
    "\n",
    "---\n",
    "\n",
    "### Why check class distribution?\n",
    "\n",
    "- **Baseline understanding:**\n",
    "  If one class has 80 samples and the other has 20, we already know the dataset is imbalanced.\n",
    "\n",
    "- **Impact on machine learning models:**\n",
    "  - In a **balanced dataset** (e.g., 50 healthy, 50 diseased), most models can learn both classes equally well.\n",
    "  - In an **imbalanced dataset** (e.g., 95 healthy, 5 diseased), a naïve model could simply predict *all samples as healthy* and still achieve 95% accuracy — but it would be useless for detecting disease.\n",
    "\n",
    "- **Evaluation metrics:**\n",
    "  With imbalanced data, **accuracy alone is misleading**.\n",
    "  We then need other metrics like **precision, recall, F1-score, ROC-AUC** to judge performance fairly.\n",
    "\n",
    "- **Synthetic data advantage:**\n",
    "  With generated data, we can **control class balance**.\n",
    "  - Want to simulate a rare disease? Generate 5% diseased, 95% healthy.\n",
    "  - Want to test fairness? Generate equal class sizes.\n",
    "\n",
    "---\n",
    "\n",
    "### What to do in this step\n",
    "1. Count how many samples belong to each class (e.g., using `value_counts()` in Pandas).\n",
    "2. Plot the counts (optional: bar chart or pie chart).\n",
    "3. Reflect: Is the dataset balanced or skewed?\n",
    "\n",
    "---\n",
    "\n",
    "### Quick Takeaway\n",
    "- Always start by checking class distribution.\n",
    "- Class balance affects how models learn and how performance should be measured.\n",
    "- Synthetic datasets let us experiment with both balanced and imbalanced cases,\n",
    "  something that is often hard with real biomedical data."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Count samples per class\n",
    "class_counts = df[\"class\"].value_counts()\n",
    "print(\"Class distribution (counts):\")\n",
    "print(class_counts)\n",
    "\n",
    "# Optional: visualize as a bar chart\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.countplot(x=\"class\", data=df, palette=\"Set1\")\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.xlabel(\"Class label\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Interpretation\n",
    "- The printed counts show how many samples belong to each class.\n",
    "- The bar chart provides a quick visual overview of balance.\n",
    "\n",
    "**Reflection**\n",
    "- Is the dataset balanced or skewed?\n",
    "- If one class dominates, how might this affect model training?\n",
    "- In biomedical research, rare diseases often mean highly imbalanced datasets.\n",
    "  How could synthetic data help simulate and study such cases?\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scatterplot of two selected features, colored by class\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(\n",
    "    data=df,\n",
    "    x=\"feature_1\",\n",
    "    y=\"feature_2\",\n",
    "    hue=\"class\",\n",
    "    palette=\"Set1\",\n",
    "    s=80\n",
    ")\n",
    "plt.title(\"Scatterplot of feature_1 vs feature_2 (colored by class)\")\n",
    "plt.xlabel(\"feature_1\")\n",
    "plt.ylabel(\"feature_2\")\n",
    "plt.legend(title=\"Class\")\n",
    "plt.show()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Interpretation\n",
    "- Each point = one sample.\n",
    "- The position shows the feature values (x = feature_1, y = feature_2).\n",
    "- The color shows the class label.\n",
    "\n",
    "If the two classes form **separate clusters**, the features are informative.\n",
    "If they **overlap**, then these features alone may not be enough for good classification.\n",
    "\n",
    "---\n",
    "\n",
    "**Reflection**\n",
    "- Try plotting different pairs of features (e.g., `feature_3` vs `feature_4`).\n",
    "  - Do some feature pairs separate the classes better than others?\n",
    "- What happens if you regenerate the dataset with a larger `class_sep` value?\n",
    "  - Does the scatterplot show clearer separation?\n",
    "- In real biomedical data, why is it rare to see perfect separation in 2D plots?\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2a.3 Scatterplot of Two Features\n",
    "\n",
    "So far, we have looked at class sizes, but not yet at how features\n",
    "help us distinguish between classes. A **scatterplot** is a simple way\n",
    "to explore **class separability** in two dimensions.\n",
    "\n",
    "---\n",
    "\n",
    "### What is a scatterplot?\n",
    "- Each **point** in the plot = one sample (e.g., one patient).\n",
    "- The **x-axis** and **y-axis** each represent a feature (e.g., biomarker_1 vs biomarker_2).\n",
    "- The **color** of each point indicates the class label (e.g., healthy = red, diseased = blue).\n",
    "\n",
    "This lets us see whether the two classes overlap or form distinct clusters.\n",
    "\n",
    "---\n",
    "\n",
    "### Why this matters\n",
    "- If the classes are **clearly separated** in the scatterplot:\n",
    "  - A simple model (like a straight line) may already do well.\n",
    "- If the classes **overlap strongly**:\n",
    "  - Classification will be harder.\n",
    "  - We may need more complex models or additional features.\n",
    "- In real biomedical data, perfect separation is rare — so synthetic data\n",
    "  gives us a safe way to practice with both easy and hard cases.\n",
    "\n",
    "---\n",
    "\n",
    "### What to do in this step\n",
    "1. Choose two feature columns (e.g., `feature_1` and `feature_2`).\n",
    "2. Plot them against each other in a scatterplot.\n",
    "3. Color the points by their class label.\n",
    "4. Inspect whether classes cluster or overlap.\n",
    "\n",
    "**Tip:** If the plot looks very mixed, try generating the data with a larger `class_sep` (e.g., `class_sep=2.0`) or choose a pair of more **informative** features.\n",
    "\n",
    "---\n",
    "\n",
    "### Quick Takeaway\n",
    "A scatterplot provides an **intuitive first view** of how separable\n",
    "two classes are. It builds intuition for what models will later try to do:\n",
    "draw a **decision boundary** that best separates the classes.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scatterplot of two selected features, colored by class\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(\n",
    "    data=df,\n",
    "    x=\"feature_1\",\n",
    "    y=\"feature_2\",\n",
    "    hue=\"class\",\n",
    "    palette=\"Set1\",\n",
    "    s=80\n",
    ")\n",
    "plt.title(\"Scatterplot of feature_1 vs feature_2 (colored by class)\")\n",
    "plt.xlabel(\"feature_1\")\n",
    "plt.ylabel(\"feature_2\")\n",
    "plt.legend(title=\"Class\")\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Interpretation\n",
    "- Each point = one sample.\n",
    "- The position shows the feature values (x = feature_1, y = feature_2).\n",
    "- The color shows the class label.\n",
    "\n",
    "If the two classes form **separate clusters**, the features are informative.\n",
    "If they **overlap**, then these features alone may not be enough for good classification.\n",
    "\n",
    "---\n",
    "\n",
    "**Reflection**\n",
    "- Try plotting different pairs of features (e.g., `feature_3` vs `feature_4`).\n",
    "  - Do some feature pairs separate the classes better than others?\n",
    "- What happens if you regenerate the dataset with a larger `class_sep` value?\n",
    "  - Does the scatterplot show clearer separation?\n",
    "- In real biomedical data, why is it rare to see perfect separation in 2D plots?\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Quick Takeaway from Lesson 2a\n",
    "\n",
    "- We can easily **generate** a synthetic dataset with controlled numbers of samples, features, and classes.\n",
    "- By checking the **class distribution**, we ensure the dataset is balanced (or intentionally imbalanced).\n",
    "- A **scatterplot of two features** gives a first intuitive sense of whether classes are separable.\n",
    "- In synthetic data, we can control how difficult separation is, which makes it a safe playground to explore basic ML concepts.\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "In the next notebook (**Lesson 2b: Feature Distributions and Effect Size**),\n",
    "we will go beyond single scatterplots and explore **all features** in more detail:\n",
    "\n",
    "- Visualize class-conditional distributions for each feature.\n",
    "- Identify which features are informative and which behave like noise.\n",
    "- Quantify differences between groups using **effect size measures** (Cohen’s d, Cliff’s delta).\n",
    "- Connect visual impressions to numeric measures of separation.\n",
    "\n",
    "➡️ Continue with: **`02b_feature_distributions_effect_size.ipynb`**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
