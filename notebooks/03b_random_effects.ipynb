{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Synthetic Biomedical Data – Lesson 3b: Random Effects (Batch / Subject Effects)\n",
    "\n",
    "Part of the *Microcredit Biomedical Data Generator* learning module.\n",
    "\n",
    "➡️ [Back to Lesson 3a: Irrelevant Features](03a_irrelevant_features.ipynb)\n",
    "➡️ [Module Overview (README)](../README.md)\n",
    "\n",
    "---"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Recap from Lesson 03a Irrelevant Features\n",
    "You:\n",
    "- Added **noise features** to a clean baseline.\n",
    "- Observed chance-driven **false discoveries** in top-k rankings.\n",
    "- Used cross-validation to quantify the stability of apparent signals."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Why this lesson: Random effects?\n",
    "\n",
    "In real biomedical studies, measurements are often collected in **batches** (different plates, days, machines, centers) or **subjects** (repeated measures). These groups induce **random effects**—systematic offsets (and sometimes slopes) that are *not* the biological signal of interest. If we ignore them, we may:\n",
    "\n",
    "- overestimate effect sizes,\n",
    "- leak information across cross-validation folds,\n",
    "- pick the wrong \"top features\",\n",
    "- and deploy models that fail in the wild.\n",
    "\n",
    "This notebook introduces random effects using controlled synthetic data, showing how they interact with class labels, how they distort metrics, and how to diagnose them early with the right CV design."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. **Simulate** batch/subject random effects on top of a clean informative dataset.\n",
    "2. **Visualize** how random intercepts shift feature distributions across batches.\n",
    "3. **Quantify** the difference between *naïve* effect sizes and *batch-corrected* effect sizes.\n",
    "4. **Prepare** the evaluation for group-aware cross-validation (e.g., `GroupKFold`) to avoid leakage in later steps.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Prerequisites & Design\n",
    "\n",
    "We build on the previous notebook (03a) that introduced **noise features**.\n",
    "Here we keep a small informative core and add **batch-level random intercepts**.\n",
    "\n",
    "**Key toggles in this notebook:**\n",
    "- `CONFOUNDED`: if `True`, batches correlate with the class (realistic worst case).\n",
    "- `BATCH_SD`: magnitude of the batch intercept shift.\n",
    "- `N_BATCHES`: number of batches to simulate.\n",
    "\n",
    "We'll first compare **global** effect sizes (ignoring batches) vs. **batch-corrected** effect sizes (demeaning per batch). In a later section, we will revisit model evaluation using **grouped CV**.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Reproducibility & plotting\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Synthetic data generator\n",
    "from biomedical_data_generator import DatasetConfig\n",
    "from biomedical_data_generator.generator import generate_dataset\n",
    "\n",
    "# Pretty display\n",
    "pd.set_option(\"display.max_rows\", 20)\n",
    "pd.set_option(\"display.width\", 120)\n",
    "\n",
    "# --- Helpers ---\n",
    "def cohen_d(x1: np.ndarray, x2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Compute Cohen's d for two independent samples.\n",
    "    Uses pooled standard deviation with Bessel's correction.\n",
    "    \"\"\"\n",
    "    x1 = np.asarray(x1, dtype=float)\n",
    "    x2 = np.asarray(x2, dtype=float)\n",
    "    n1, n2 = len(x1), len(x2)\n",
    "    if n1 < 2 or n2 < 2:\n",
    "        return 0.0\n",
    "    m1, m2 = x1.mean(), x2.mean()\n",
    "    s1, s2 = x1.std(ddof=1), x2.std(ddof=1)\n",
    "    # pooled SD\n",
    "    s_pooled = np.sqrt(((n1 - 1) * s1**2 + (n2 - 1) * s2**2) / (n1 + n2 - 2))\n",
    "    return (m1 - m2) / s_pooled if s_pooled > 0 else 0.0\n",
    "\n",
    "\n",
    "def effect_sizes_by_feature(X: pd.DataFrame, y: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute |Cohen's d| for all columns in X between classes y in {0,1}.\n",
    "    Returns a sorted DataFrame.\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    x0 = X[y == 0]\n",
    "    x1 = X[y == 1]\n",
    "    for col in X.columns:\n",
    "        out[col] = abs(cohen_d(x0[col].values, x1[col].values))\n",
    "    df = pd.DataFrame.from_dict(out, orient=\"index\", columns=[\"|Cohen_d|\"]).sort_values(\"|Cohen_d|\", ascending=False)\n",
    "    df.index.name = \"Feature\"\n",
    "    return df\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- Core dataset parameters (keep small and interpretable) ---\n",
    "N_SAMPLES   = 240\n",
    "N_INFORM    = 8\n",
    "N_PSEUDO    = 0\n",
    "N_NOISE     = 6\n",
    "N_CLASSES   = 2\n",
    "CLASS_SEP   = 1.2\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# --- Random-effects parameters ---\n",
    "N_BATCHES   = 4\n",
    "BATCH_SD    = 1.0     # magnitude of random intercept per batch\n",
    "CONFOUNDED  = True    # if True, batches correlate with the class label (worst case)\n",
    "AFFECTED    = \"all\"   # \"all\" or \"informative\" — which features receive batch offsets\n",
    "\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cfg = DatasetConfig(\n",
    "    n_samples=N_SAMPLES,\n",
    "    n_informative=N_INFORM,\n",
    "    n_pseudo=N_PSEUDO,\n",
    "    n_noise=N_NOISE,\n",
    "    n_classes=N_CLASSES,\n",
    "    class_sep=CLASS_SEP,\n",
    "    feature_naming=\"prefixed\",  # i1, i2, ..., n1, ...\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "# Return DataFrame for convenience in EDA\n",
    "X, y, meta = generate_dataset(cfg, return_dataframe=True)\n",
    "\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "display(X.head(3))\n",
    "\n",
    "# Feature lists\n",
    "informative_cols = [c for c in X.columns if c.startswith(\"i\")]\n",
    "noise_cols       = [c for c in X.columns if c.startswith(\"n\")]\n",
    "feature_cols     = informative_cols + noise_cols  # (no pseudo in this notebook)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def assign_batches(y: pd.Series, n_batches: int, confounded: bool, p_major: float = 0.7, seed: int = 0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Create a batch assignment for samples.\n",
    "    If confounded=True, class 1 is overrepresented in batches {0,1} and class 0 in {2,3} (for n_batches=4),\n",
    "    controlled by p_major.\n",
    "    \"\"\"\n",
    "    rng_local = np.random.default_rng(seed)\n",
    "    y = y.values.astype(int)\n",
    "    n = len(y)\n",
    "\n",
    "    if not confounded:\n",
    "        return rng_local.integers(0, n_batches, size=n)\n",
    "\n",
    "    # Simple confounding scheme for n_batches >= 2\n",
    "    major_for_1 = list(range(min(2, n_batches)))               # e.g., batches 0,1\n",
    "    major_for_0 = list(range(2, min(4, n_batches))) or [0]     # e.g., batches 2,3 (fallback 0)\n",
    "\n",
    "    batches = np.empty(n, dtype=int)\n",
    "    for i, yi in enumerate(y):\n",
    "        if yi == 1:\n",
    "            if rng_local.random() < p_major:\n",
    "                batches[i] = rng_local.choice(major_for_1)\n",
    "            else:\n",
    "                others = [b for b in range(n_batches) if b not in major_for_1]\n",
    "                batches[i] = rng_local.choice(others or major_for_1)\n",
    "        else:\n",
    "            if rng_local.random() < p_major:\n",
    "                batches[i] = rng_local.choice(major_for_0)\n",
    "            else:\n",
    "                others = [b for b in range(n_batches) if b not in major_for_0]\n",
    "                batches[i] = rng_local.choice(others or major_for_0)\n",
    "    return batches\n",
    "\n",
    "batch_id = assign_batches(y, n_batches=N_BATCHES, confounded=CONFOUNDED, p_major=0.75, seed=RANDOM_SEED)\n",
    "X[\"batch_id\"] = batch_id\n",
    "\n",
    "# Quick sanity checks\n",
    "print(\"Class counts:\", dict(pd.Series(y).value_counts().sort_index()))\n",
    "print(\"Batch counts:\", dict(pd.Series(batch_id).value_counts().sort_index()))\n",
    "print(\"Contingency (batch × class):\")\n",
    "display(pd.crosstab(X[\"batch_id\"], y))\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Choose which columns receive batch offsets\n",
    "if AFFECTED == \"informative\":\n",
    "    cols_to_shift = informative_cols\n",
    "else:\n",
    "    cols_to_shift = feature_cols\n",
    "\n",
    "# Draw one intercept per batch (same for all affected features)\n",
    "batch_intercepts = rng.normal(loc=0.0, scale=BATCH_SD, size=N_BATCHES)\n",
    "\n",
    "X_shifted = X.copy()\n",
    "for b in range(N_BATCHES):\n",
    "    mask = X_shifted[\"batch_id\"].values == b\n",
    "    X_shifted.loc[mask, cols_to_shift] = X_shifted.loc[mask, cols_to_shift] + batch_intercepts[b]\n",
    "\n",
    "# Keep original for comparison\n",
    "X_raw = X[feature_cols].copy()\n",
    "X = X_shifted  # from here on, X contains random-effects shifts\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Pick a few representative features to visualize\n",
    "show_cols = (informative_cols[:3] + noise_cols[:3])[:6]\n",
    "\n",
    "n_rows, n_cols = 2, 3\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 8), constrained_layout=True)\n",
    "\n",
    "for i, col in enumerate(show_cols):\n",
    "    ax = axes[i // n_cols, i % n_cols]\n",
    "    sns.histplot(\n",
    "        data=pd.DataFrame({col: X[col], \"class_\": y, \"batch_id\": X[\"batch_id\"]}),\n",
    "        x=col, hue=\"class_\", stat=\"density\", element=\"step\", common_norm=False, alpha=0.3, kde=True, ax=ax,\n",
    "    )\n",
    "    ax.set_title(f\"{col} — by class (batches mixed)\")\n",
    "    ax.set_ylabel(\"Density\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Facet by batch for the first feature to see the intercept shifts clearly\n",
    "col = show_cols[0]\n",
    "g = sns.FacetGrid(pd.DataFrame({col: X[col], \"class_\": y, \"batch_id\": X[\"batch_id\"]}), col=\"batch_id\", col_wrap=4, sharex=True, sharey=True, height=3)\n",
    "g.map_dataframe(sns.kdeplot, x=col, hue=\"class_\", common_norm=False, fill=False)\n",
    "g.add_legend()\n",
    "g.fig.suptitle(f\"Batch-wise KDE for {col}\", y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1) Naïve (global) effect sizes\n",
    "es_global = effect_sizes_by_feature(X[feature_cols], y)\n",
    "display(es_global.head(10))\n",
    "\n",
    "# 2) Batch-corrected effect sizes via per-batch demeaning (random-intercept removal)\n",
    "X_bc = X[feature_cols].copy()\n",
    "for col in feature_cols:\n",
    "    X_bc[col] = X_bc[col] - X.groupby(\"batch_id\")[col].transform(\"mean\")\n",
    "\n",
    "es_batch_corrected = effect_sizes_by_feature(X_bc, y)\n",
    "display(es_batch_corrected.head(10))\n",
    "\n",
    "# Compare both views side-by-side for the top features\n",
    "cmp = es_global.join(es_batch_corrected, lsuffix=\"_global\", rsuffix=\"_batch_corrected\")\n",
    "cmp = cmp.sort_values(\"|Cohen_d|_global\", ascending=False)\n",
    "display(cmp.head(15))\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Interim Takeaways\n",
    "\n",
    "- **Random intercepts** can make features look strongly discriminative in a *global* view, especially when batches are **confounded** with the class.\n",
    "- **Per-batch demeaning** (a simple random-intercept removal) often shrinks those inflated effect sizes.\n",
    "- This is an EDA-stage warning sign: if rankings flip after batch correction, you likely need **group-aware cross-validation** and possibly **mixed-effects models** or dedicated batch-correction strategies.\n",
    "\n",
    "**Next:** Evaluate models with **`GroupKFold`** (group = `batch_id`) vs. naïve CV to see real-world impact on performance."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Why compare two CV schemes now?\n",
    "\n",
    "We just saw how random intercepts inflate global effect sizes. The next step is to check whether model **evaluation** is also biased. We will run the **same pipeline** under two CV schemes:\n",
    "\n",
    "- **Naïve StratifiedKFold** (leaky wrt batches)\n",
    "- **GroupKFold** with `group = batch_id` (out-of-batch generalization)\n",
    "\n",
    "**Expectation:** If batches are confounded and/or batch SD is large, naïve CV will report **optimistic** scores compared to group-aware CV."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Models & CV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, cross_validate\n",
    "\n",
    "# Use only the feature matrix (no batch_id) for modeling\n",
    "X_mat = X[feature_cols].values\n",
    "y_arr = y.values\n",
    "groups = X[\"batch_id\"].values  # used only in GroupKFold\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(solver=\"lbfgs\", max_iter=1000, random_state=RANDOM_SEED)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Two evaluation schemes: naïve (leaky w.r.t. batches) vs. grouped (batch-safe)\n",
    "cv_naive   = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_SEED)\n",
    "cv_grouped = GroupKFold(n_splits=min(N_BATCHES, 5))\n",
    "\n",
    "scoring = {\"bal_acc\": \"balanced_accuracy\", \"roc_auc\": \"roc_auc\"}\n",
    "\n",
    "# Naïve CV (no grouping)\n",
    "res_naive = cross_validate(\n",
    "    pipe, X_mat, y_arr,\n",
    "    cv=cv_naive,\n",
    "    scoring=scoring,\n",
    "    n_jobs=-1,\n",
    "    return_estimator=False,\n",
    ")\n",
    "\n",
    "# Group-aware CV (groups = batch_id)\n",
    "res_group = cross_validate(\n",
    "    pipe, X_mat, y_arr,\n",
    "    cv=cv_grouped,\n",
    "    groups=groups,\n",
    "    scoring=scoring,\n",
    "    n_jobs=-1,\n",
    "    return_estimator=False,\n",
    ")\n",
    "\n",
    "def summarize(res, label):\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"scheme\": [label, label],\n",
    "            \"metric\": [\"balanced_accuracy\", \"roc_auc\"],\n",
    "            \"mean\":   [res[\"test_bal_acc\"].mean(), res[\"test_roc_auc\"].mean()],\n",
    "            \"std\":    [res[\"test_bal_acc\"].std(ddof=1), res[\"test_roc_auc\"].std(ddof=1)],\n",
    "        }\n",
    "    )\n",
    "\n",
    "summary = pd.concat([summarize(res_naive, \"naive\"), summarize(res_group, \"grouped\")], ignore_index=True)\n",
    "summary\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Visualizing the gap\n",
    "\n",
    "A compact plot helps to internalize the gap between the two evaluation schemes. If the bar for \"naïve\" sits clearly above \"grouped\", you have evidence of **batch leakage**.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bar plot for balanced accuracy means with error bars (±1 SD)\n",
    "plot_df = summary[summary[\"metric\"] == \"balanced_accuracy\"].copy()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "ax.bar(plot_df[\"scheme\"], plot_df[\"mean\"], yerr=plot_df[\"std\"], capsize=5)\n",
    "ax.set_ylabel(\"Balanced accuracy (CV)\")\n",
    "ax.set_title(\"Naïve vs. Group-aware CV\")\n",
    "for i, v in enumerate(plot_df[\"mean\"]):\n",
    "    ax.text(i, v, f\"{v:.3f}\", ha=\"center\", va=\"bottom\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# (Optional) Also display ROC-AUC table rounded\n",
    "display(summary.pivot(index=\"scheme\", columns=\"metric\", values=\"mean\").round(3))\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### What do misclassifications look like?\n",
    "\n",
    "Confusion matrices make the leakage tangible. If the naïve CV predicts much better than the grouped CV, your model likely learned batch structure instead of true biology. This validates the need for **group-aware** evaluation (and later, proper batch handling)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Naïve predictions\n",
    "y_pred_naive = cross_val_predict(pipe, X_mat, y_arr, cv=cv_naive, method=\"predict\")\n",
    "# Group-aware predictions\n",
    "y_pred_group = cross_val_predict(pipe, X_mat, y_arr, cv=cv_grouped, groups=groups, method=\"predict\")\n",
    "\n",
    "print(\"Naïve CV — classification report\")\n",
    "print(classification_report(y_arr, y_pred_naive, digits=3))\n",
    "\n",
    "print(\"\\nGroup-aware CV — classification report\")\n",
    "print(classification_report(y_arr, y_pred_group, digits=3))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4), constrained_layout=True)\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_arr, y_pred_naive)).plot(ax=axes[0], colorbar=False)\n",
    "axes[0].set_title(\"Naïve CV\")\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(y_arr, y_pred_group)).plot(ax=axes[1], colorbar=False)\n",
    "axes[1].set_title(\"Group-aware CV\")\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Recap & Interpretation\n",
    "\n",
    "- **Random intercepts** shift feature distributions per batch; when confounded with the class, both **effect sizes** and **naïve CV** are inflated.\n",
    "- **GroupKFold** approximates out-of-batch generalization and typically reduces overly optimistic metrics.\n",
    "- **EDA signals to watch:**\n",
    "  - Feature ranks change after per-batch demeaning.\n",
    "  - Naïve > grouped CV, often by a sizeable margin.\n",
    "- **Actionable next steps** (not all implemented here):\n",
    "  - Always use **group-aware CV** when batches/subjects exist.\n",
    "  - Consider **batch-correction** or **mixed-effects modeling** when appropriate for your downstream analysis.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercises (Try this)\n",
    "\n",
    "1. **Change one knob at a time**\n",
    "   - Increase `BATCH_SD` (e.g., 0.2 → 1.0 → 1.8). Observe how the naïve–grouped gap grows.\n",
    "   - Toggle `CONFOUNDED=True/False`. When does the gap almost vanish?\n",
    "   - Switch `AFFECTED` between `\"informative\"` and `\"all\"`. Which case hurts robustness more?\n",
    "\n",
    "2. **Different grouping granularity**\n",
    "   - Increase `N_BATCHES`. Does more (smaller) batches change the gap?\n",
    "   - Try **Leave-One-Batch-Out** (LOBO) by setting `n_splits = N_BATCHES` in `GroupKFold`.\n",
    "\n",
    "3. **Model sensitivity**\n",
    "   - Replace Logistic Regression with **LinearSVC**, **RandomForest**, or **XGBoost**. Which model is most/least sensitive to batch leakage?\n",
    "\n",
    "4. **Feature stability**\n",
    "   - Compute top-k features by |Cohen’s d| on raw vs. batch-demeaned data and measure **Precision@k** overlap.\n",
    "\n",
    "5. **Reporting**\n",
    "   - Summarize in 3–5 sentences what setting(s) lead to the largest leakage and how grouped CV fixes it.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import StratifiedKFold, GroupKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def make_dataset_with_random_effects(\n",
    "    n_samples=N_SAMPLES,\n",
    "    n_inform=N_INFORM,\n",
    "    n_noise=N_NOISE,\n",
    "    n_classes=N_CLASSES,\n",
    "    class_sep=CLASS_SEP,\n",
    "    n_batches=N_BATCHES,\n",
    "    batch_sd=0.0,\n",
    "    confounded=False,\n",
    "    affected=AFFECTED,\n",
    "    seed=RANDOM_SEED,\n",
    "):\n",
    "    cfg = DatasetConfig(\n",
    "        n_samples=n_samples,\n",
    "        n_informative=n_inform,\n",
    "        n_pseudo=0,\n",
    "        n_noise=n_noise,\n",
    "        n_classes=n_classes,\n",
    "        class_sep=class_sep,\n",
    "        feature_naming=\"prefixed\",\n",
    "        random_state=seed,\n",
    "    )\n",
    "    X0, y0, _ = generate_dataset(cfg, return_dataframe=True)\n",
    "    inf_cols = [c for c in X0.columns if c.startswith(\"i\")]\n",
    "    noise_cols = [c for c in X0.columns if c.startswith(\"n\")]\n",
    "    feat_cols = inf_cols + noise_cols\n",
    "\n",
    "    batches = assign_batches(y0, n_batches=n_batches, confounded=confounded, p_major=0.75, seed=seed)\n",
    "    X0[\"batch_id\"] = batches\n",
    "\n",
    "    rng_local = np.random.default_rng(seed)\n",
    "    shifts = rng_local.normal(0.0, batch_sd, size=n_batches)\n",
    "\n",
    "    if affected == \"informative\":\n",
    "        cols_to_shift = inf_cols\n",
    "    else:\n",
    "        cols_to_shift = feat_cols\n",
    "\n",
    "    X_shift = X0.copy()\n",
    "    for b in range(n_batches):\n",
    "        mask = X_shift[\"batch_id\"].values == b\n",
    "        X_shift.loc[mask, cols_to_shift] = X_shift.loc[mask, cols_to_shift] + shifts[b]\n",
    "\n",
    "    return X_shift, y0, feat_cols, batches\n",
    "\n",
    "\n",
    "def eval_cv_gap(batch_sd_grid=(0.0, 0.5, 1.0, 1.5), confounded=True, seed=RANDOM_SEED):\n",
    "    rows = []\n",
    "    for sd in batch_sd_grid:\n",
    "        Xs, ys, fcols, groups = make_dataset_with_random_effects(batch_sd=sd, confounded=confounded, seed=seed)\n",
    "        X_mat = Xs[fcols].values\n",
    "        y_arr = ys.values\n",
    "\n",
    "        pipe = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                         (\"clf\", LogisticRegression(max_iter=1000, random_state=seed))])\n",
    "\n",
    "        cv_naive   = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "        cv_grouped = GroupKFold(n_splits=min(len(np.unique(groups)), 5))\n",
    "\n",
    "        scoring = {\"bal_acc\": \"balanced_accuracy\", \"roc_auc\": \"roc_auc\"}\n",
    "\n",
    "        res_naive = cross_validate(pipe, X_mat, y_arr, cv=cv_naive, scoring=scoring, n_jobs=-1)\n",
    "        res_group = cross_validate(pipe, X_mat, y_arr, cv=cv_grouped, groups=groups, scoring=scoring, n_jobs=-1)\n",
    "\n",
    "        rows.append({\n",
    "            \"batch_sd\": sd,\n",
    "            \"confounded\": confounded,\n",
    "            \"bal_acc_naive\": res_naive[\"test_bal_acc\"].mean(),\n",
    "            \"bal_acc_group\": res_group[\"test_bal_acc\"].mean(),\n",
    "            \"roc_auc_naive\": res_naive[\"test_roc_auc\"].mean(),\n",
    "            \"roc_auc_group\": res_group[\"test_roc_auc\"].mean(),\n",
    "        })\n",
    "    return pd.DataFrame(rows).sort_values(\"batch_sd\")\n",
    "\n",
    "# Quick demo\n",
    "df_sweep = eval_cv_gap(batch_sd_grid=[0.0, 0.4, 0.8, 1.2, 1.6], confounded=True)\n",
    "display(df_sweep.round(3))\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "ax.plot(df_sweep[\"batch_sd\"], df_sweep[\"bal_acc_naive\"], marker=\"o\", label=\"naive (bal_acc)\")\n",
    "ax.plot(df_sweep[\"batch_sd\"], df_sweep[\"bal_acc_group\"], marker=\"o\", label=\"grouped (bal_acc)\")\n",
    "ax.set_xlabel(\"Batch SD\")\n",
    "ax.set_ylabel(\"Balanced accuracy (CV)\")\n",
    "ax.set_title(\"Effect of batch strength on naïve vs. grouped CV\")\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Leave-One-Batch-Out (LOBO)\n",
    "\n",
    "For `n_splits = N_BATCHES`, `GroupKFold` becomes LOBO. This is a strong out-of-batch estimate when batches are a realistic deployment boundary (e.g., new day / new plate / new center).\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import GroupKFold, cross_val_score\n",
    "\n",
    "X_mat = X[feature_cols].values\n",
    "y_arr = y.values\n",
    "groups = X[\"batch_id\"].values\n",
    "\n",
    "pipe = Pipeline([(\"scaler\", StandardScaler()),\n",
    "                 (\"clf\", LogisticRegression(max_iter=1000, random_state=RANDOM_SEED))])\n",
    "\n",
    "cv_lobo = GroupKFold(n_splits=N_BATCHES)\n",
    "scores = cross_val_score(pipe, X_mat, y_arr, cv=cv_lobo, groups=groups, scoring=\"balanced_accuracy\", n_jobs=-1)\n",
    "print(f\"LOBO balanced accuracy: mean={scores.mean():.3f} ± {scores.std(ddof=1):.3f}\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Beyond LOBO: handling batches without information leakage\n",
    "\n",
    "LOBO shows the *evaluation* side. Next we contrast two preprocessing strategies:\n",
    "\n",
    "1) **Leaky global batch demeaning** (WRONG): remove per-batch means using the **entire dataset** before CV.\n",
    "2) **Fold-aware batch demeaning** (CORRECT): compute batch means **on the training fold only**, apply them to the test fold (unseen batches get no shift).\n",
    "\n",
    "Goal: see how leakage inflates scores and confirm the safe alternative.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Quick Takeaways\n",
    "\n",
    "- **Random effects create structure** (batch/subject-specific offsets) that can inflate both **effect sizes** and **naïve CV** scores.\n",
    "- If batches are **confounded** with the class, naïve CV becomes **optimistic**; **GroupKFold** approximates out-of-batch generalization.\n",
    "- A simple **per-batch demeaning** shrinks inflated effect sizes and is a useful EDA probe (not a full correction).\n",
    "- Always align your **CV scheme with the deployment boundary** (new day/plate/center/subject ⇒ grouped CV or LOBO).\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Common pitfalls (and how to avoid them)\n",
    "\n",
    "**1) Wrong CV scheme**\n",
    "- *Pitfall:* Using `StratifiedKFold` (or plain `KFold`) when batches/subjects exist → **leakage**.\n",
    "- *Fix:* Use `GroupKFold` or `LeaveOneGroupOut` (LOBO). If available in your sklearn version, prefer `StratifiedGroupKFold` to keep class balance across grouped folds.\n",
    "\n",
    "**2) Preprocessing before the split**\n",
    "- *Pitfall:* Fitting scaler/imputer/PCA/feature selection on the **entire dataset** prior to CV.\n",
    "- *Fix:* Put **all preprocessing inside a `Pipeline`** and let CV fit it **only on the training folds**.\n",
    "\n",
    "**3) Batch demeaning as a “correction”**\n",
    "- *Pitfall:* Applying per-batch demeaning on the full data and then doing CV → still leaks test-fold info.\n",
    "- *Fix:* Treat per-batch demeaning as **EDA only** in this notebook. If you must use it in modeling, implement a **group-aware transformer** that fits means on the train fold and applies them to train/test separately.\n",
    "\n",
    "**4) Using `batch_id` as a feature**\n",
    "- *Pitfall:* Including `batch_id` in `X` → the model learns batch labels, not biology.\n",
    "- *Fix:* Keep `batch_id` **only for grouping**, never as a predictor.\n",
    "\n",
    "**5) Ignoring class imbalance within groups**\n",
    "- *Pitfall:* `GroupKFold` does not stratify; some folds can be skewed.\n",
    "- *Fix:* Check fold distributions. Use `StratifiedGroupKFold` if available, or adjust `class_weight='balanced'` and use **balanced accuracy**.\n",
    "\n",
    "**6) Tuning vs. evaluation mismatch**\n",
    "- *Pitfall:* Hyperparameter search with naïve CV, but final reporting with grouped CV (or vice versa).\n",
    "- *Fix:* **Align your selection CV with your evaluation CV** (both grouped). For reliable performance estimates, use **nested CV** with groups.\n",
    "\n",
    "**7) Too few batches**\n",
    "- *Pitfall:* Very small number of groups → high variance estimates; tempting to revert to naïve CV.\n",
    "- *Fix:* Prefer **LOBO** (one batch per test fold) and **report uncertainty** (mean ± SD). Consider collecting more batches if possible.\n",
    "\n",
    "**8) Data augmentation / resampling leakage**\n",
    "- *Pitfall:* Over/under-sampling, SMOTE, or augmentations applied before CV.\n",
    "- *Fix:* Wrap any resampling step **inside the Pipeline** and ensure it runs **only on the training fold**.\n",
    "\n",
    "**9) Feature engineering outside the split**\n",
    "- *Pitfall:* Computing interactions/filters on the full dataset.\n",
    "- *Fix:* Same rule: **inside the Pipeline**.\n",
    "\n",
    "**10) Not checking confounding**\n",
    "- *Pitfall:* Assuming batches are harmless.\n",
    "- *Fix:* Always inspect `crosstab(batch, class)` and compute a dependence measure (e.g., **Cramér’s V**). Large values → expect naïve > grouped gap.\n",
    "\n",
    "**11) Reporting the wrong number**\n",
    "- *Pitfall:* Quoting training metrics or a single lucky split.\n",
    "- *Fix:* Report **CV means ± SD**, prefer **balanced accuracy** / **ROC-AUC** over plain accuracy when classes are imbalanced.\n",
    "\n",
    "**12) Uncontrolled randomness**\n",
    "- *Pitfall:* Mixed RNG states across NumPy/sklearn; irreproducible results.\n",
    "- *Fix:* Set `random_state` (model, CV shuffles, dataset generator) and log versions/seeds.\n",
    "\n",
    "---\n",
    "\n",
    "### Quick self-check (before you trust the numbers)\n",
    "- ✅ `GroupKFold`/LOBO (or `StratifiedGroupKFold`) used for **both tuning and evaluation**\n",
    "- ✅ All preprocessing inside a **Pipeline**\n",
    "- ✅ `batch_id` used **only** for grouping, not as a feature\n",
    "- ✅ **Naïve vs. grouped** gap inspected; Cramér’s V computed\n",
    "- ✅ Results reported as **mean ± SD** over folds; code is **seeded** and versions logged\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1) Quantify confounding between batch and class (Cramér's V) ---\n",
    "\n",
    "def cramers_v(table: pd.DataFrame) -> float:\n",
    "    obs = table.values.astype(float)\n",
    "    n = obs.sum()\n",
    "    if n == 0:\n",
    "        return 0.0\n",
    "    row = obs.sum(axis=1, keepdims=True)\n",
    "    col = obs.sum(axis=0, keepdims=True)\n",
    "    expected = row @ col / n\n",
    "    # Avoid division by zero for empty cells\n",
    "    mask = expected > 0\n",
    "    chi2 = ((obs - expected)[mask] ** 2 / expected[mask]).sum()\n",
    "    r, k = obs.shape\n",
    "    denom = n * (min(r - 1, k - 1))\n",
    "    return float(np.sqrt(chi2 / denom)) if denom > 0 else 0.0\n",
    "\n",
    "ct = pd.crosstab(X[\"batch_id\"], y)\n",
    "V = cramers_v(ct)\n",
    "print(\"Contingency table (batch × class):\")\n",
    "display(ct)\n",
    "print(f\"Cramér's V = {V:.3f}  (rule of thumb: ~0.1 small, ~0.3 medium, ~0.5 large)\")\n",
    "\n",
    "# --- 2) Leakage guardrail based on CV results ---\n",
    "\n",
    "# Expect 'summary' from Cell 12 to be present: columns = [scheme, metric, mean, std]\n",
    "def get_mean(summary_df: pd.DataFrame, scheme: str, metric: str) -> float:\n",
    "    sel = summary_df[(summary_df[\"scheme\"] == scheme) & (summary_df[\"metric\"] == metric)]\n",
    "    return float(sel[\"mean\"].iloc[0]) if not sel.empty else float(\"nan\")\n",
    "\n",
    "ba_naive = get_mean(summary, \"naive\", \"balanced_accuracy\")\n",
    "ba_group = get_mean(summary, \"grouped\", \"balanced_accuracy\")\n",
    "gap = ba_naive - ba_group\n",
    "\n",
    "print(f\"\\nBalanced accuracy — naive: {ba_naive:.3f}, grouped: {ba_group:.3f}, gap: {gap:.3f}\")\n",
    "\n",
    "# Soft guardrail: flag suspicious optimism\n",
    "THRESH = 0.08  # tweak for your course; 0.05–0.10 are common teaching thresholds\n",
    "if np.isfinite(gap) and gap > THRESH:\n",
    "    print(\"⚠️  Guardrail: Naïve CV is notably higher than grouped CV. Likely batch leakage.\")\n",
    "else:\n",
    "    print(\"✓ Guardrail: No substantial naïve > grouped gap detected.\")\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exercises\n",
    "\n",
    "1) **One knob at a time**\n",
    "- Sweep `BATCH_SD` (e.g., 0.0 → 0.4 → 0.8 → 1.2 → 1.6). Track the naive–grouped gap.\n",
    "- Toggle `CONFOUNDED=True/False`. When does the gap nearly vanish?\n",
    "- Switch `AFFECTED` between `\"informative\"` and `\"all\"`. Which hurts generalization more?\n",
    "\n",
    "2) **Granularity of groups**\n",
    "- Increase `N_BATCHES`. Does having many small batches change the gap?\n",
    "- Try **LOBO** (`GroupKFold(n_splits=N_BATCHES)`) to simulate strict out-of-batch testing.\n",
    "\n",
    "3) **Model sensitivity**\n",
    "- Replace Logistic Regression with `LinearSVC`, `RandomForestClassifier`, or `XGBoost`.\n",
    "- Which model is most sensitive to batch leakage in your setup?\n",
    "\n",
    "4) **Feature stability**\n",
    "- Rank top-k by |Cohen’s d| before vs. after per-batch demeaning and compute **Precision@k** overlap.\n",
    "\n",
    "5) **Short report (5–8 sentences)**\n",
    "- Describe the settings that produced the largest leakage and how grouped CV mitigated it.\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Next Steps\n",
    "\n",
    "- **Pseudo-signals (03c):** Move from random intercepts to structured artifacts (hidden subclasses / pseudo features).\n",
    "- **Correlated features (03d):** Study redundancy and multicollinearity; compare L1, Elastic Net, and tree-based importances.\n",
    "- **Advanced handling (beyond this notebook):**\n",
    "  - Mixed-effects models (random intercepts/slopes) for repeated measures.\n",
    "  - Batch-aware preprocessing/normalization if domain-appropriate.\n",
    "  - Stability analysis of selected features across grouped splits."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
