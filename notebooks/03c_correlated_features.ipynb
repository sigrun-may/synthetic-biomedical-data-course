{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:white;\" >\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"float: left; width: 14%; padding: 5px; height:auto\">\n",
    "    <img src=\"img/TUBraunschweig_CO_200vH_300dpi.jpg\" alt=\"TU_Braunschweig\" style=\"width:100%\">\n",
    "  </div>\n",
    "  <div style=\"float: left; width: 28%; padding: 5px; height:auto\">\n",
    "    <img src=\"img/TU_Clausthal_Logo.png\" alt=\"TU_Clausthal\" style=\"width:100%\">\n",
    "  </div>\n",
    "  <div style=\"float: left; width: 25%; padding: 5px; height:auto\">\n",
    "    <img src=\"img/ostfalia.jpg\" alt=\"Ostfalia\" style=\"width:100%\">\n",
    "  </div>\n",
    "  <div style=\"float: left; width: 21%; padding: 5px;\">\n",
    "    <img src=\"img/niedersachsen_rgb_whitebg.png\" alt=\"Niedersachsen\" style=\"width:100%\">\n",
    "  </div>\n",
    "  <div style=\"float: left; width: 9%; padding: 5px;\">\n",
    "    <img src=\"img/internet_BMBF_gefoerdert_2017_en.jpg\" alt=\"bmbf\" style=\"width:100%\">\n",
    "  </div>\n",
    "</div>\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"img/ki4all.jpg\" alt=\"KI4ALL-Logo\" width=\"200\"/>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Biomedical Data ‚Äì Lesson 3: Advanced Data Generation\n",
    "Part of the *Microcredit Artificial Data Generator* module.\n",
    "\n",
    "‚û°Ô∏è [Back to Lesson 3b: Irrelevant Features - noise distributions](03b_noise_distributions.ipynb)\n",
    "‚û°Ô∏è [Module README](../README.md)\n",
    "\n",
    "*Before continuing, please ensure you reviewed the prerequisites and learning goals in Lesson 1.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 3c: Correlated Features (Biological Pathways)\n",
    "\n",
    "### Recap\n",
    "Previously, you learned that not all features are informative.\n",
    "Spurious correlations between noise features and the label can arise by chance, especially as dimensionality increases.\n",
    "Now we explore what happens when features are redundant because they move together.\n",
    "\n",
    "\n",
    "### Why this lesson: Correlated features?\n",
    "In real biomedical data, features are often not independent. Biological processes often involve groups of molecules that move together. Biological examples include:\n",
    "- Genes in the same pathway may be co-expressed (e.g., Gene A and Gene B always expressed together).\n",
    "- Proteins in a signaling cascade may be activated together.\n",
    "- Metabolites in the same biochemical pathway are chemically linked, and their concentrations co-vary.\n",
    "\n",
    "These dependencies create correlated features in real datasets. Strong correlations can:\n",
    "- Reduce the unique information each feature provides\n",
    "- Create instability in model training and feature importance\n",
    "- Mislead or complicate model training and feature selection\n",
    "\n",
    "Synthetic data allows us to add and control correlations. By simulating them in synthetic data, we can study their impact on visualization, classification, and feature selection under known ground truth.\n",
    "\n",
    "### Key terms\n",
    "- **Feature correlation**: statistical association between features (e.g., Pearson correlation).\n",
    "- **Cluster / module**: a group of features that co-vary.\n",
    "- **Co-variation**: features that change together across samples.\n",
    "- **Equicorrelation**: all features in a cluster have nearly the same pairwise correlation.\n",
    "- **AR(1) / Toeplitz**: correlation decays with distance in feature index.\n",
    "- **Redundancy**: multiple features carry nearly the same information.\n",
    "- **Anchor** (driver): the feature that primarily carries the class signal in a cluster.\n",
    "- **Proxies**: followers that correlate with the anchor and partially mirror its information.\n",
    "- **Multicollinearity**: strong feature correlations that make individual coefficients unstable (especially in linear models).\n",
    "- **Attribution ambiguity (non-identifiability of individual effects)**: when several correlated features predict equally well, importance can be spread or exchanged among them.\n",
    "\n",
    "### What you'll learn\n",
    "After completing this notebook, you will be able to:\n",
    "- Generate pathway-like clusters of features with a tunable correlation (e.g., equicorrelated or AR(1)/Toeplitz structure).\n",
    "- Compose a dataset by mixing correlated blocks with independent features to reach a target dimensionality p.\n",
    "- Visualize and interpret the empirical correlation matrix.\n",
    "- Explain practical implications (redundancy, multicollinearity, non-identifiability of individual effects, proxy features) and recommend mitigation strategies (grouped selection, stability checks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Step 1: Code ‚Äì Imports, Installation/Upgrade"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# If needed, install or upgrade the package biomedical-data-generator(uncomment in managed environments) via:\n",
    "# %pip install -U biomedical-data-generator"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Standard package imports\n",
    "import nb_imports as nb\n",
    "\n",
    "# Set plotting style\n",
    "from nb_setup import apply_style\n",
    "\n",
    "apply_style()\n",
    "\n",
    "rng = nb.np.random.default_rng(42)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Step 2. Generate synthetic data with correlated feature clusters\n"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.1 Equicorrelated Feature Cluster\n",
    "\n",
    "**Equicorrelated features**: A correlation structure where all pairwise correlations are similar (œÅ). There are no \"special pairs\" ‚Äì all features are equally connected to all others. While rare in nature, understanding this extreme case helps us recognize feature redundancy problems."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For a cluster of k features X‚ÇÅ, X‚ÇÇ, ..., X‚Çñ, the equicorrelated structure means:\n",
    "\n",
    "**Correlation Matrix**\n",
    "```\n",
    "     X‚ÇÅ   X‚ÇÇ   X‚ÇÉ   ...\n",
    "X‚ÇÅ [ 1    œÅ    œÅ   ... ]\n",
    "X‚ÇÇ [ œÅ    1    œÅ   ... ]\n",
    "X‚ÇÉ [ œÅ    œÅ    1   ... ]\n",
    "...\n",
    "```\n",
    "All pairwise correlations are identical:\n",
    "\n",
    "- Cor(X·µ¢, X‚±º) = œÅ for all i ‚â† j\n",
    "- Cor(X·µ¢, X·µ¢) = 1 (self-correlation is always 1)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üß¨ Where Do We Find Equicorrelated Structures?\n",
    "Imagine a group of biomarkers that all \"move together\":\n",
    "- If one goes up, all others tend to go up too\n",
    "- If one goes down, all others follow\n",
    "- Every pair has about the same correlation œÅ (rho)\n",
    "\n",
    "#### Example 1: Transcription Factor Target Genes\n",
    "Genes regulated by the same transcription factor often correlate\n",
    "highly because:\n",
    "- They respond to the same upstream signal via shared regulatory elements\n",
    "- Coordinated expression serves a common biological goal\n",
    "\n",
    "**Clinical implication:** Highly correlated features often have\n",
    "similar predictive value‚Äîselecting \"the best\" single feature\n",
    "becomes somewhat arbitrary without biological context.\n",
    "\n",
    "#### Example 2: Imaging-Derived Features\n",
    "Radiomics features from the same tissue region:\n",
    "- Texture features (homogeneity, entropy, contrast) derived from\n",
    "  overlapping pixel sets\n",
    "- Mathematically related through shared image statistics\n",
    "- High redundancy not obvious from feature names\n",
    "\n",
    "**Research challenge:** Different texture features may be selected\n",
    "across folds despite capturing similar information‚Äîcomplicating\n",
    "biological interpretation."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Generate and Visualize"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Generate equicorrelated cluster\n",
    "equicorrelated_cluster = nb.sample_cluster(\n",
    "    n_samples=30,\n",
    "    n_features=10,\n",
    "    rng=rng,\n",
    "    structure=\"equicorrelated\",\n",
    "    rho=0.9,\n",
    ")\n",
    "correlation_matrix, labels = nb.compute_correlation_matrix(nb.pd.DataFrame(equicorrelated_cluster))\n",
    "\n",
    "# plot the heatmap\n",
    "fig, ax = nb.plot_correlation_matrix(\n",
    "    # Compute correlation matrix from cluster_data\n",
    "    correlation_matrix=correlation_matrix,\n",
    "    labels=labels,\n",
    "    title=\"Equicorrelated Cluster (œÅ=0.7)\",\n",
    "    annot=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Equicorrelated cluster ‚Äî how to read this heatmap\n",
    "\n",
    "**What you see**\n",
    "\n",
    "All off-diagonal entries are close to the same value. The diagonal is exactly 1. Small deviations from perfect uniformity arise due to limited sample size.\n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "This block represents a one-factor (shared-signal) structure: every feature carries the same latent component, so any pair of features is similarly correlated. Unique information per feature is limited and largely redundant.\n",
    "\n",
    "An equicorrelated block encodes a single shared biological signal (e.g., a co-regulated module). It‚Äôs ideal for studying how structured redundancy affects learnability, interpretability, and stability in high-dimensional settings."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Why This Matters for Machine Learning\n",
    "- High œÅ ‚Üí features are nearly redundant (multicollinearity)\n",
    "- Feature selection becomes non-identifiable: any cluster member\n",
    "  can serve as proxy for the others\n",
    "- Including 10 highly correlated texture features\n",
    "doesn't give you \"10√ó more information\" ‚Äì it inflates feature\n",
    "importance scores and destabilizes selection."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2.2 Toeplitz/AR(1) Feature Cluster: When Distance Matters\n",
    "\n",
    "**Toeplitz/AR(1) features**: A correlation structure where correlation decays exponentially with distance (œÅ^|i-j|). Features have a natural ordering (sequence, time, position), and only nearby features share strong redundancy. Common in real biological data‚Äîgene expression cascades, chromosomal neighborhoods, metabolic pathways‚Äîmaking it essential for realistic synthetic benchmarks."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Terminology: Toeplitz vs. AR(1)\n",
    "\n",
    "We use two equivalent terms depending on the domain context. Both terms describe the same correlation matrix.\n",
    "\n",
    "#### **Toeplitz Structure** (Linear Algebra)\n",
    "Toeplitz describes the mathematical form of the correlation matrix where diagonals are constant and features have a **\"near/far\"** relationship without directionality.\n",
    "\n",
    "#### **AR(1) Process** (Time Series)\n",
    "AR(1) describes a data-generating mechanism where each value depends on its predecessor:\n",
    "\n",
    "$$X_t = \\rho \\cdot X_{t-1} + \\varepsilon_t$$\n",
    "\n",
    "This autoregressive process naturally produces Toeplitz correlation.\n",
    "Features have a **\"before/after\"** relationship with directionality. Examples are temporal dynamics (time series, cascades) or sequential processes (metabolic pathways)."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### The Correlation Pattern\n",
    "\n",
    "When features have positional or temporal ordering, correlation typically decays exponentially with distance:\n",
    "\n",
    "$$\\text{Cor}(X_i, X_j) = \\rho^{|i-j|}$$\n",
    "\n",
    "This creates a localized \"neighborhood\" structure:\n",
    "- **Immediate neighbors** (distance 1): correlation = œÅ\n",
    "- **Next-door neighbors** (distance 2): correlation = œÅ¬≤\n",
    "- **Distant features** (distance k): correlation = œÅ^k"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "For a cluster of k features X‚ÇÅ, X‚ÇÇ, ..., X‚Çñ, the Toeplitz/AR(1) structure means:\n",
    "\n",
    "**Correlation Matrix R**\n",
    "```\n",
    "     X‚ÇÅ    X‚ÇÇ    X‚ÇÉ    X‚ÇÑ   ...\n",
    "X‚ÇÅ [ 1     œÅ     œÅ¬≤    œÅ¬≥  ... ]\n",
    "X‚ÇÇ [ œÅ     1     œÅ     œÅ¬≤  ... ]\n",
    "X‚ÇÉ [ œÅ¬≤    œÅ     1     œÅ   ... ]\n",
    "X‚ÇÑ [ œÅ¬≥    œÅ¬≤    œÅ     1   ... ]\n",
    "...\n",
    "```\n",
    "**Distance-dependent correlation:**\n",
    "- Cor(X·µ¢, X·µ¢‚Çä‚ÇÅ) = œÅ (neighbors)\n",
    "- Cor(X·µ¢, X·µ¢‚Çä‚ÇÇ) = œÅ¬≤ (distance 2)\n",
    "- Cor(X·µ¢, X·µ¢‚Çä‚Çñ) = œÅ^k (distance k)\n",
    "-\n",
    "**Example:** With œÅ = 0.7:\n",
    "- Cor(X‚ÇÅ, X‚ÇÇ) = 0.70 (strong)\n",
    "- Cor(X‚ÇÅ, X‚ÇÉ) = 0.49 (moderate)\n",
    "- Cor(X‚ÇÅ, X‚ÇÖ) = 0.24 (weak)\n",
    "- Cor(X‚ÇÅ, X‚ÇÅ‚ÇÄ) = 0.03 (negligible)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üß¨ Where Do We Find the Toeplitz/AR(1) Pattern?\n",
    "\n",
    "Biomarker groups with inherent positional or temporal structure:\n",
    "\n",
    "- **Gene expression cascades**: Upstream genes regulate downstream genes\n",
    "- **Chromosomal position**: Nearby genes share regulatory elements\n",
    "- **Metabolic pathways**: Sequential enzymatic steps\n",
    "- **Temporal measurements**: Hormone levels throughout a circadian cycle\n",
    "- **Spatial transcriptomics**: Gene expression from adjacent tissue regions\n",
    "\n",
    "In each case, correlation decays with distance."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Generate and Visualize"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Generate Toeplitz/AR(1) cluster (mimics sequential regulatory cascade)\n",
    "toeplitz_cluster = nb.sample_cluster(\n",
    "    n_samples=30,\n",
    "    n_features=10,\n",
    "    rng=rng,\n",
    "    structure=\"toeplitz\",  # Changed from \"equicorrelated\"\n",
    "    rho=0.7,  # Lag-1 correlation; correlation decays as œÅ^k with distance\n",
    ")\n",
    "correlation_matrix, labels = nb.compute_correlation_matrix(nb.pd.DataFrame(toeplitz_cluster))\n",
    "\n",
    "# plot the heatmap\n",
    "fig, ax = nb.plot_correlation_matrix(\n",
    "    correlation_matrix=correlation_matrix,\n",
    "    labels=labels,\n",
    "    title=\"Toeplitz/AR(1) Cluster (œÅ=0.7)\",\n",
    "    annot=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Toeplitz / AR(1) cluster ‚Äî how to read this heatmap\n",
    "\n",
    "**What you see**\n",
    "\n",
    "The diagonal is 1 by definition. Correlations are strongest near this main diagonal and decay with distance from it. This shows a banded pattern where nearby features are highly correlated, and distant features have low correlation. Small variations from the ideal pattern occur due to limited sample size. With unlimited samples, the empirical correlations would match the theoretical Toeplitz structure exactly.\n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "Nearby features share more signal than distant ones. This creates a \"neighborhood\" structure where redundancy is localized. Features share information primarily with their immediate neighbors, not the entire cluster. This reflects biological processes where local dependencies dominate, such as gene expression cascades or chromosomal neighborhoods."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Why This Matters for Machine Learning\n",
    "\n",
    "1. **Localized Feature selection instability**: Correlated neighbors are interchangeable\n",
    "2. **Interpretation challenges**: Which gene in a chromosomal region is \"causal\" vs. just a correlated neighbor?\n",
    "3. **Overfitting via redundant neighborhoods**: High-dimensional data with multiple local clusters creates many correlated pathways\n",
    "4. **Realistic benchmarks**: Real biomarker panels often have this structure\n",
    "\n",
    "**Key difference from equicorrelated features:**\n",
    "- Redundancy is local, not global ‚Üí distant features (e.g., Feature 1 and Feature 100) add independent information\n",
    "- Multicollinearity still present, but localized to neighborhoods ‚Üí not every feature competes with every other\n",
    "- Selection stability improves between neighborhoods ‚Üí choosing one feature from each cluster is more reproducible"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Explore Correlation Strength\n",
    "**Task:** Modify the code above to generate clusters with different œÅ values (0.3, 0.7, 0.95).\n",
    "- How does the heatmap change?\n",
    "- At what œÅ do features become practically redundant?\n",
    "- What implications does this have for feature selection?\n",
    "\n",
    "**Expected output:** Three heatmaps showing different correlation strengths."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Step 3. Generate a Dataset with Two Correlated Clusters and High-Dimensional Noise\n",
    "\n",
    "From isolated clusters to full data set: We now generate a complete p‚â´n dataset (1225 features, 120 samples) with the `biomedical-data-generator` where two small correlated pathways carry class information while being drowned in high-dimensional noise. This reflects the challenge biomedical researchers face‚Äîfinding signal among overwhelming irrelevant variation.\n",
    "\n",
    "In each of the two pathways, only one feature (the \"anchor\") truly differs between classes. The other features are correlated \"proxies\" that follow their anchor without their own class effect. This reveals how correlation makes many features appear important even when only a few are causal.\n",
    "\n",
    "#### Generator Settings\n",
    "* **Samples and classes**\n",
    "\n",
    "  >`n_samples=120`, balanced `class_counts={0: 60, 1: 60}` for stable comparisons.\n",
    "\n",
    "* **Correlated clusters** (`corr_clusters`)\n",
    "  >- **Pathway A** (10 features): Equicorrelated with `rho=0.7` ‚Äî all pairs share identical correlation (global redundancy).\n",
    "  >- **Pathway B** (15 features): Toeplitz with `rho=0.6` ‚Äî correlation decays with distance (Cor(X_i, X_j) ‚âà œÅ^|i-j|), which mimics local dependencies.\n",
    "\n",
    "\n",
    "* **Anchors vs. proxies**\n",
    "\n",
    "  >`anchor_role=\"informative\"` makes the first feature in each pathway the class-informative anchor. All other features in that pathway are correlated proxies without their own class shift.\n",
    "\n",
    "* **Effect sizes**\n",
    "\n",
    "  >`anchor_effect_size=\"medium\"` gives moderate separation for the two anchors. `class_sep=1.2` scales the overall task difficulty‚Äîhigh enough to require modeling, low enough to avoid trivial perfect separation.\n",
    "\n",
    "* **Informative feature count**\n",
    "\n",
    "  >`n_informative=2` ‚Äî exactly the two pathway anchors. No additional standalone informative features.\n",
    "\n",
    "* **High-dimensional noise**\n",
    "\n",
    "  >`n_noise=1200` adds independent features unrelated to class, creating realistic p‚â´n conditions (1225 features vs. 120 samples).\n",
    "\n",
    "* **Pathway independence**\n",
    "\n",
    "  >`corr_between=0.0` keeps the two pathways uncorrelated, creating visually distinct blocks in correlation heatmaps.\n",
    "\n",
    "* **Reproducibility**\n",
    "\n",
    "  >`random_state=42`. Feature names use `feature_naming=\"prefixed\"` ‚Üí expect `i1`, `i2` (anchors), `corr1_1`, `corr1_2`, ..., `corr2_1`, ..., `n1`, `n2`, ... (noise)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "cfg = nb.DatasetConfig(\n",
    "    n_samples=120,\n",
    "    n_classes=2,\n",
    "    class_counts={0: 60, 1: 60},  # required by the generator\n",
    "    # Correlated clusters (anchors are the only informative features in each cluster)\n",
    "    corr_clusters=[\n",
    "        nb.CorrClusterConfig(\n",
    "            n_cluster_features=6,\n",
    "            structure=\"equicorrelated\",\n",
    "            rho=0.7, # rho=0.7 is typical for co-regulated genes under same transcription factor\n",
    "            anchor_role=\"informative\",  # first column is the informative \"anchor\"\n",
    "            anchor_effect_size=\"large\",  # shift strength for the anchor\n",
    "            anchor_class=0,  # one-vs-rest effect (defaults to 0 if omitted)\n",
    "            label=\"Pathway A (equicorr)\",\n",
    "        ),\n",
    "        nb.CorrClusterConfig(\n",
    "            n_cluster_features=8,\n",
    "            structure=\"toeplitz\",\n",
    "            rho=0.6,\n",
    "            anchor_role=\"informative\",\n",
    "            anchor_effect_size=\"medium\",\n",
    "            anchor_class=1,  # anchor targets class 1 here\n",
    "            label=\"Pathway B (toeplitz)\",\n",
    "        ),\n",
    "    ],\n",
    "    # Important: n_informative must include the number of informative anchors\n",
    "    n_informative=2,  # exactly 2 anchors above ‚Üí no extra free informative features\n",
    "    n_pseudo=0,  # no additional free pseudo features; proxies come from clusters\n",
    "    n_noise=1200,  # a bit of extra noise to make p>n\n",
    "    noise_distribution=nb.NoiseDistribution.normal,\n",
    "    noise_scale=1.0,\n",
    "    class_sep=1.2,  # modest separation so redundancy/correlation still matters\n",
    "    anchor_mode=\"equalized\",\n",
    "    corr_between=0.0,  # keep clusters independent for clarity\n",
    "    feature_naming=\"prefixed\",  # i1, corr1_2, ..., n1, n2, ...\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "x, y, meta = nb.generate_dataset(cfg, return_dataframe=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Plot the correlation heatmap"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "fig, ax = nb.plot_all_correlation_clusters(df=x, correlation_method = \"spearman\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Interpreting the Correlation Structure\n",
    "\n",
    "The heatmap visualizes the **empirical pairwise correlations** between all features across two simulated clusters:\n",
    "- **Cluster 1 (left block)** follows an *equicorrelated* structure ‚Äî every pair of features shares approximately the same correlation. This produces a uniform bright block, reflecting a single shared latent factor that drives all features equally.\n",
    "- **Cluster 2 (right block)** follows a *Toeplitz (AR-1)* structure ‚Äî correlations decay gradually with feature distance from the anchor. This creates a banded pattern where nearby features are strongly correlated, and distant ones less so.\n",
    "\n",
    "**Interpretation**\n",
    "- Within each cluster, features move together to varying degrees, mimicking biological pathways or co-regulated gene modules.\n",
    "- The near-zero correlations between clusters confirm that they are **independent by design**.\n",
    "- Diagonal values are 1 by definition (self-correlation).\n",
    "- Small deviations from the idealized pattern arise from **finite-sample variability**.\n",
    "\n",
    "Controlled correlation structures allow us to systematically study how **redundancy**, **multicollinearity**, and **proxy features** influence model performance and feature selection stability in high-dimensional biomedical data."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Try It Yourself\n",
    "Create a dataset where:\n",
    "- Cluster 1 has 20 features with œÅ=0.9 (equicorrelated)\n",
    "- Cluster 2 has 15 features with œÅ=0.5 (Toeplitz)\n",
    "- Add 500 noise features\n",
    "- Visualize the correlation structure\n",
    "\n",
    "Can you identify both clusters in the heatmap?"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Typical pitfalls you'll observe with correlated features\n",
    "Correlated features introduce several challenges in machine learning pipelines, especially in biomedical contexts where pathways and co-regulated modules are common. Here are some typical pitfalls:\n",
    "### Feature selection issues:\n",
    "\n",
    "* Redundant picks: Selectors choose many proxies from one anchor cluster ‚Üí low diversity, inflated feature counts\n",
    "* Unstable rankings: Correlated features swap positions across resamples/CV folds ‚Üí unreliable interpretation\n",
    "* Split votes: Selection algorithms \"distribute\" importance across cluster members instead of identifying the anchor\n",
    "* Masked coefficients: In linear models, coefficients shrink or flip sign under strong collinearity ‚Üí misleading effect sizes\n",
    "\n",
    "### Model evaluation traps:\n",
    "* Leakage via feature selection: Selecting features on full data before CV ‚Üí overly optimistic performance estimates\n",
    "* Group structure ignored: Random CV splits batches/sites between train and test ‚Üí artificially high scores when batch effects exist\n",
    "* Metric blindness: Accuracy looks great even when model relies entirely on one correlated cluster (or noise with lucky correlation)\n",
    "* Overfitting to correlation structure: Model memorizes which features \"travel together\" rather than learning true class signal\n",
    "\n",
    "### Cross-validation failures:\n",
    "**Correlation-specific issues:**\n",
    "* Instability across folds: Different CV folds select different correlated features\n",
    "  ‚Üí model composition changes unpredictably\n",
    "\n",
    "**General p‚â´n issues (worsened by correlation):**\n",
    "* Feature selection leakage: Standard k-fold CV combined with feature selection\n",
    "  on full data ‚Üí information leaks from test into training\n",
    "* Nested CV is necessary but often skipped ‚Üí hyperparameter tuning leaks information\n",
    "* Small sample size (n=50‚Äì100) + many features (p=500) ‚Üí high variance in CV\n",
    "  estimates, single splits misleading\n",
    "\n",
    "\n",
    "## Why generate correlated features for benchmarking?\n",
    "Correlated features stress-test the entire ML pipeline in ways uncorrelated synthetic data cannot:\n",
    "### 1. Expose feature selection fragility\n",
    "\n",
    "* Methods like Lasso, mRMR, or univariate filters must decide which cluster member to pick\n",
    "* Different seeds/resamples ‚Üí different choices ‚Üí unstable gene/biomarker lists\n",
    "* Ground truth benefit: You know features 0‚Äì9 are informative; if the selector picks features 11, 23, 45 (all correlated noise), you can prove it failed\n",
    "\n",
    "### 2. Test model robustness to multicollinearity\n",
    "\n",
    "* Linear models: do regularization methods (Ridge, Lasso, ElasticNet) correctly handle redundancy?\n",
    "* Tree-based models: are they truly \"immune\" to correlation, or do they still split votes across cluster members?\n",
    "* Controlled comparison: Generate identical class separation with r=0.0, 0.5, 0.9 ‚Üí observe degradation\n",
    "\n",
    "### 3. Reveal metric blind spots\n",
    "\n",
    "* A model using only one noisy cluster member can achieve AUC=0.85 if that member happens to correlate with the outcome\n",
    "* Permutation baselines become critical: shuffle class labels ‚Üí does performance drop? If not, model found spurious structure\n",
    "* Correlation amplifies the risk of \"good metrics, bad model\"\n",
    "\n",
    "### 4. Force proper cross-validation discipline\n",
    "\n",
    "* With correlated features, naive CV (select features ‚Üí split ‚Üí train) always leaks information\n",
    "* Nested CV is the only valid approach, but it's computationally expensive and often skipped in practice\n",
    "* Synthetic benchmark: Train students/researchers to detect and avoid this mistake with data where you can quantify the bias\n",
    "\n",
    "### 5. Simulate biological pathway structure\n",
    "\n",
    "* Real biomedical data has correlated features (gene co-expression, metabolic pathways, protein complexes)\n",
    "* Uncorrelated synthetic data is too clean ‚Üí models perform unrealistically well, then fail on real data\n",
    "* Realism test: If a method can't handle r=0.7‚Äì0.9 in synthetic data, it won't handle real biological pathways\n",
    "\n",
    "### 6. Enable stability analysis\n",
    "\n",
    "* Run 100 bootstrap resamples ‚Üí measure Jaccard stability, Kuncheva index\n",
    "* Expected outcome: Correlated features ‚Üí low stability (‚âà0.3‚Äì0.5), uncorrelated ‚Üí high stability (‚âà0.8)\n",
    "* Provides quantitative benchmark: \"This feature selection method is unstable under correlation\"\n",
    "\n",
    "\n",
    "# Quick takeaway\n",
    "### Correlated features are:\n",
    "\n",
    "* Biologically realistic (genes/proteins don't act independently)\n",
    "* Statistically challenging (violate standard assumptions)\n",
    "* Pedagogically valuable (make invisible pitfalls visible through controlled experiments)\n",
    "\n",
    "Without correlation in synthetic data, learners miss the most common real-world failure modes. Generating Toeplitz/AR(1) clusters is relevant to explore how correlation strength (œÅ) and cluster size affect model behavior and feature selection stability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "In **Lesson 3d: Non-Causal Variation**, you will:\n",
    "- Add **batch effects** and **pseudo-classes** (site, instrument, eye color) to simulate non-causal subgroups.\n",
    "- Create **confounding** where models learn subgroup membership instead of biology.\n",
    "- Expose the failure of **Random CV** and learn when **Group CV** is essential.\n",
    "\n",
    "‚û°Ô∏è Continue with: **[`03d_non_causal_variation.ipynb`](03d_non_causal_variation.ipynb)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
