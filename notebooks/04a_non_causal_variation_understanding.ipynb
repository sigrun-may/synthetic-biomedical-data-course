{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:white;\" >\n",
    "<div style=\"clear: both; display: table;\">\n",
    "  <div style=\"float: left; width: 14%; padding: 5px; height:auto\">\n",
    "    <img src=\"img/TUBraunschweig_CO_200vH_300dpi.jpg\" alt=\"TU_Braunschweig\" style=\"width:100%\">\n",
    "  </div>\n",
    "  <div style=\"float: left; width: 28%; padding: 5px; height:auto\">\n",
    "    <img src=\"img/TU_Clausthal_Logo.png\" alt=\"TU_Clausthal\" style=\"width:100%\">\n",
    "  </div>\n",
    "  <div style=\"float: left; width: 25%; padding: 5px; height:auto\">\n",
    "    <img src=\"img/ostfalia.jpg\" alt=\"Ostfalia\" style=\"width:100%\">\n",
    "  </div>\n",
    "  <div style=\"float: left; width: 21%; padding: 5px;\">\n",
    "    <img src=\"img/niedersachsen_rgb_whitebg.png\" alt=\"Niedersachsen\" style=\"width:100%\">\n",
    "  </div>\n",
    "  <div style=\"float: left; width: 9%; padding: 5px;\">\n",
    "    <img src=\"img/internet_BMBF_gefoerdert_2017_en.jpg\" alt=\"bmbf\" style=\"width:100%\">\n",
    "  </div>\n",
    "</div>\n",
    "<div style=\"text-align:center\">\n",
    "<img src=\"img/ki4all.jpg\" alt=\"KI4ALL-Logo\" width=\"200\"/>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Biomedical Data â€“ Lesson 4: Non-Causal Variation\n",
    "Part of the *Microcredit Artificial Data Generator* module.\n",
    "\n",
    "â¡ï¸ [Back to Lesson 3c: Correlated Features](03c_correlated_features.ipynb)\n",
    "â¡ï¸ [Module README](../README.md)\n",
    "\n",
    "*Before continuing, please ensure you reviewed the prerequisites and learning goals in Lesson 1.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4a: Understanding Non-Causal Variation and Confounding\n",
    "\n",
    "### Recap\n",
    "In previous lessons, you learned to generate synthetic biomedical datasets with:\n",
    "- Informative features that carry true class signals\n",
    "- Noise features that are irrelevant\n",
    "- Correlated feature clusters mimicking biological pathways\n",
    "\n",
    "These elements reflect **causal biology**: features that directly relate to the disease or outcome of interest. However, real-world biomedical data contains an additional layer of complexity that has nothing to do with biology: **non-causal variation**.\n",
    "\n",
    "### Why this lesson matters: The hidden danger in biomedical data\n",
    "\n",
    "Imagine a study where:\n",
    "- Site A recruited mostly healthy controls\n",
    "- Site B recruited mostly diseased patients\n",
    "- Both sites used different measurement instruments\n",
    "\n",
    "Your model achieves 95% accuracy! But is it learning biology or just detecting which site the sample came from? This is **confounding** â€“ when a non-causal factor (site) is inadvertently associated with the outcome (disease status).\n",
    "\n",
    "Non-causal variation is one of the most common reasons why:\n",
    "- Models fail to generalize to new sites or cohorts\n",
    "- Biomarker discoveries don't replicate in independent studies\n",
    "- Published ML models never make it to clinical practice\n",
    "\n",
    "This lesson teaches you to recognize, understand, and eventually simulate these artifacts so you can:\n",
    "- Design robust evaluation strategies\n",
    "- Test whether your method learns real biology or memorizes artifacts\n",
    "- Develop models that generalize beyond the training cohort\n",
    "\n",
    "### Key terms\n",
    "- **Non-causal variation / artifacts**: systematic differences in data that are unrelated to the biological outcome of interest.\n",
    "- **Batch effects**: technical variation from sample processing (e.g., different lab personnel, reagent lots, measurement dates).\n",
    "- **Site effects**: systematic differences between data collection sites (e.g., hospitals, research centers).\n",
    "- **Instrument effects**: variation from different measurement devices or protocols.\n",
    "- **Recruitment artifacts**: imbalances in how patients were selected or enrolled (e.g., time periods, eligibility criteria).\n",
    "- **Pseudo-class / spurious subgroup**: a group that looks like a biological class but is actually driven by non-causal factors.\n",
    "- **Confounding**: when a non-causal factor correlates with (or even perfectly predicts) the outcome, creating a spurious association.\n",
    "- **Perfect confounding**: when site/batch membership completely determines class label (e.g., all controls from Site A, all cases from Site B).\n",
    "- **Partial confounding**: when site/batch membership is strongly but not perfectly associated with class.\n",
    "- **Leakage (in this context)**: when a model learns to predict non-causal subgroup membership instead of the true biological outcome.\n",
    "- **Distributional shift**: when test data comes from a different distribution than training data (e.g., new site, new instrument).\n",
    "\n",
    "### What you'll learn\n",
    "After completing this notebook, you will be able to:\n",
    "- Distinguish between causal biological variation and non-causal artifacts.\n",
    "- Identify common sources of non-causal variation in biomedical studies.\n",
    "- Explain what confounding means and why it's dangerous for machine learning.\n",
    "- Recognize the difference between perfect and partial confounding.\n",
    "- Understand why standard random cross-validation fails under confounding.\n",
    "- Articulate the consequences of models that learn artifacts instead of biology.\n",
    "- Appreciate why synthetic data with controlled confounding is essential for method testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: What is Non-Causal Variation?\n",
    "\n",
    "## The Nature of Biomedical Data Collection\n",
    "\n",
    "Biomedical data is rarely collected under perfectly controlled laboratory conditions. Instead, it accumulates through:\n",
    "- **Multi-site studies**: Different hospitals or research centers contribute samples\n",
    "- **Multi-batch processing**: Samples are processed in groups over time\n",
    "- **Equipment upgrades**: Measurement technology changes during a study\n",
    "- **Protocol variations**: Slight differences in sample handling or preparation\n",
    "- **Time-dependent factors**: Seasonal effects, personnel changes, reagent lot variations\n",
    "\n",
    "Each of these introduces **systematic differences** in the measured features that have nothing to do with the biological question.\n",
    "\n",
    "## Causal vs. Non-Causal Features\n",
    "\n",
    "To understand the distinction, consider a cancer classification problem:\n",
    "\n",
    "### Causal variation (what we want to learn):\n",
    "```\n",
    "Gene X expression â†’ Tumor growth â†’ Cancer diagnosis\n",
    "â†‘                                   â†‘\n",
    "Biological cause                    Outcome\n",
    "```\n",
    "- Gene X is **mechanistically related** to cancer\n",
    "- Expression level **varies with** disease state\n",
    "- Relationship holds across **different populations and settings**\n",
    "\n",
    "### Non-causal variation (what we want to avoid learning):\n",
    "```\n",
    "Site A: Old instrument â†’ Lower measured values\n",
    "Site B: New instrument â†’ Higher measured values\n",
    "\n",
    "Site A recruited: 80% healthy, 20% cancer\n",
    "Site B recruited: 20% healthy, 80% cancer\n",
    "```\n",
    "- Measurement differences are **technical artifacts**\n",
    "- Site membership **correlates with** disease status by chance (or flawed study design)\n",
    "- Relationship is **specific to this dataset** and won't generalize\n",
    "\n",
    "## Visualization: The Confounding Trap\n",
    "\n",
    "Let's visualize what happens when non-causal variation confounds the outcome:\n",
    "\n",
    "```\n",
    "Scenario 1: No Confounding (Ideal)\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Site A:  ğŸ”µğŸ”µğŸ”µ ğŸ”´ğŸ”´ğŸ”´  (50% healthy, 50% cancer)\n",
    "Site B:  ğŸ”µğŸ”µğŸ”µ ğŸ”´ğŸ”´ğŸ”´  (50% healthy, 50% cancer)\n",
    "Site C:  ğŸ”µğŸ”µğŸ”µ ğŸ”´ğŸ”´ğŸ”´  (50% healthy, 50% cancer)\n",
    "\n",
    "â†’ Site membership tells us nothing about disease status\n",
    "â†’ Models must learn biology to classify correctly\n",
    "\n",
    "\n",
    "Scenario 2: Perfect Confounding (Disaster)\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Site A:  ğŸ”µğŸ”µğŸ”µğŸ”µğŸ”µğŸ”µ  (100% healthy)\n",
    "Site B:  ğŸ”´ğŸ”´ğŸ”´ğŸ”´ğŸ”´ğŸ”´  (100% cancer)\n",
    "Site C:  ğŸ”µğŸ”µğŸ”µğŸ”µğŸ”µğŸ”µ  (100% healthy)\n",
    "\n",
    "â†’ Site membership perfectly predicts disease!\n",
    "â†’ Model can achieve 100% accuracy by learning site markers\n",
    "â†’ Biology is irrelevant\n",
    "\n",
    "\n",
    "Scenario 3: Partial Confounding (Common in practice)\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Site A:  ğŸ”µğŸ”µğŸ”µğŸ”µğŸ”µ ğŸ”´     (85% healthy, 15% cancer)\n",
    "Site B:  ğŸ”µ ğŸ”´ğŸ”´ğŸ”´ğŸ”´ğŸ”´     (15% healthy, 85% cancer)\n",
    "Site C:  ğŸ”µğŸ”µ ğŸ”´ğŸ”´ğŸ”´ğŸ”´     (30% healthy, 70% cancer)\n",
    "\n",
    "â†’ Site membership is informative but not deterministic\n",
    "â†’ Model has incentive to learn both site markers AND biology\n",
    "â†’ Hard to disentangle: which features are causal?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Question 1\n",
    "\n",
    "Consider a genomic study where:\n",
    "- Site A collected samples in 2015 using instrument 1\n",
    "- Site B collected samples in 2020 using a new instrument 2\n",
    "- Both sites studied the same disease vs. healthy comparison\n",
    "\n",
    "**Question**: List at least three sources of non-causal variation that could exist between these two sites, even if the underlying biology is identical.\n",
    "\n",
    "<details>\n",
    "<summary>Click to see example answers</summary>\n",
    "\n",
    "**Technical sources**:\n",
    "1. **Sequencing depth**: The different instruments could produce more/ fewer reads per sample\n",
    "2. **Base calling accuracy**: Newer technology could have improved error rates\n",
    "3. **GC bias patterns**: Different instruments have characteristic biases\n",
    "4. **Library preparation protocols**: May have changed over 5 years\n",
    "\n",
    "**Biological sources (non-causal to disease)**:\n",
    "5. **Population demographics**: Different geographic regions may have genetic background differences\n",
    "6. **Age distribution**: Enrollment criteria may have shifted\n",
    "7. **Comorbidities**: Healthcare practice changes over time\n",
    "\n",
    "**Operational sources**:\n",
    "8. **Sample storage time**: Site A samples stored 5 years longer\n",
    "9. **Personnel**: Different lab technicians, protocols, quality control\n",
    "10. **Reagent lots**: Different batches of chemicals and enzymes\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Common Sources of Non-Causal Variation\n",
    "\n",
    "## 2.1 Batch Effects\n",
    "\n",
    "**Definition**: Technical variation introduced by sample processing in groups (batches).\n",
    "\n",
    "### Typical scenarios:\n",
    "- **Microarray/RNA-seq**: Samples processed on different days or by different personnel\n",
    "- **Mass spectrometry**: Instrument calibration drifts between runs\n",
    "- **Flow cytometry**: Reagent lot changes, temperature variations\n",
    "- **Clinical chemistry**: Different analyzer calibrations\n",
    "\n",
    "### Characteristics:\n",
    "- Affects **all features** in a batch simultaneously (though with varying strength)\n",
    "- Can be **additive** (constant shift) or **multiplicative** (scaling)\n",
    "- May have **non-linear effects** (batch Ã— feature interactions)\n",
    "- Often **partially confounded** with outcome if batches processed samples based on availability\n",
    "\n",
    "### Example:\n",
    "```\n",
    "Batch 1 (January):  Controls processed first (40 samples)\n",
    "Batch 2 (February): Mixed (20 controls, 20 cases)\n",
    "Batch 3 (March):    Cases processed last (40 samples)\n",
    "\n",
    "â†’ Batch membership is partially confounded with disease status\n",
    "â†’ Model might learn: \"High expression in batch 3 = cancer\"\n",
    "â†’ Reality: Batch 3 had different reagent lot that artificially inflated values\n",
    "```\n",
    "\n",
    "## 2.2 Site Effects\n",
    "\n",
    "**Definition**: Systematic differences between data collection centers.\n",
    "\n",
    "### Typical scenarios:\n",
    "- **Multi-center clinical trials**: Different hospitals use different equipment\n",
    "- **Consortium studies**: Each lab has its own protocols\n",
    "- **Meta-analyses**: Combining published datasets from different sources\n",
    "\n",
    "### Characteristics:\n",
    "- Can include **all batch effect types** (technical + operational)\n",
    "- May include **population differences** (demographics, genetics)\n",
    "- Often have **strong confounding** if sites specialize (e.g., cancer center vs. general hospital)\n",
    "- Hardest to correct because sites differ in **multiple unmeasured ways**\n",
    "\n",
    "### Example:\n",
    "```\n",
    "Site A (University Hospital):    Recruited severe cases\n",
    "Site B (Community Clinic):       Recruited mild cases + controls\n",
    "Site C (Preventive Care Center): Recruited only healthy controls\n",
    "\n",
    "â†’ Perfect confounding: Site C has 0% cases\n",
    "â†’ Model learns to recognize Site C markers â†’ predicts \"healthy\"\n",
    "â†’ When applied to new Site D: model fails completely\n",
    "```\n",
    "\n",
    "## 2.3 Instrument and Protocol Effects\n",
    "\n",
    "**Definition**: Variation from different measurement technologies or procedures.\n",
    "\n",
    "### Typical scenarios:\n",
    "- **Technology upgrades**: Study switches from microarray to RNA-seq mid-way\n",
    "- **Vendor differences**: Roche vs. Abbott vs. Siemens diagnostic assays\n",
    "- **Protocol versions**: Sample prep updated based on manufacturer recommendations\n",
    "\n",
    "### Characteristics:\n",
    "- Creates **discrete subgroups** in feature space\n",
    "- May affect **specific feature subsets** (e.g., only low-abundance proteins)\n",
    "- Confounding occurs if instrument change **coincides with** changes in patient recruitment\n",
    "\n",
    "## 2.4 Time-Dependent Artifacts\n",
    "\n",
    "**Definition**: Variation that correlates with time (recruitment year, processing date).\n",
    "\n",
    "### Typical scenarios:\n",
    "- **Seasonal effects**: Vitamin D levels vary by season\n",
    "- **Enrollment period**: Early vs. late recruitment in longitudinal study\n",
    "- **Secular trends**: Disease definition changes (e.g., diagnostic criteria updates)\n",
    "- **Storage duration**: Sample degradation over years\n",
    "\n",
    "### Why it's dangerous:\n",
    "```\n",
    "Year 1: Recruited 80% controls (study startup phase)\n",
    "Year 2: Recruited 50% controls, 50% cases (full enrollment)\n",
    "Year 3: Recruited 20% controls (mostly cases by end)\n",
    "\n",
    "â†’ Year correlates with disease prevalence\n",
    "â†’ Year also correlates with sample age (degradation)\n",
    "â†’ Model learns temporal markers instead of disease biology\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Question 2\n",
    "\n",
    "**Scenario**: You're analyzing a proteomics dataset where:\n",
    "- Samples from 2018-2019 were measured on Instrument A\n",
    "- Instrument A broke down in 2020\n",
    "- Samples from 2020-2021 were measured on Instrument B (same technology, different unit)\n",
    "- Disease prevalence was roughly constant across all years\n",
    "\n",
    "**Question**: \n",
    "1. Is this an example of confounding? Why or why not?\n",
    "2. Would random cross-validation give you an accurate estimate of model performance? Why?\n",
    "3. What evaluation strategy would be more appropriate?\n",
    "\n",
    "<details>\n",
    "<summary>Click to see answer</summary>\n",
    "\n",
    "**Answer 1**: **No, this is NOT confounding** (at least not with disease status). Since disease prevalence is constant across years, instrument membership does not predict the outcome. However, it is still a **distributional shift** that could affect generalization.\n",
    "\n",
    "**Answer 2**: **Yes, random CV would likely give accurate estimates** because:\n",
    "- Each CV fold would contain a mix of both instruments\n",
    "- The model can learn instrument-invariant features\n",
    "- Test set distribution matches training set distribution\n",
    "\n",
    "**However**, random CV would NOT tell you whether the model generalizes to:\n",
    "- A new Instrument C at a different site\n",
    "- Samples measured exclusively on Instrument A or B\n",
    "\n",
    "**Answer 3**: More appropriate strategies:\n",
    "- **Instrument-aware CV**: Train on Instrument A, test on Instrument B (and vice versa)\n",
    "- **Temporal CV**: Train on 2018-2019, test on 2020-2021\n",
    "- **Sensitivity analysis**: Compare performance with and without instrument correction\n",
    "\n",
    "This illustrates an important point: **Not all non-causal variation is confounding, but it can still pose generalization challenges.**\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: The Mechanics of Confounding\n",
    "\n",
    "## What Makes Confounding Dangerous?\n",
    "\n",
    "Confounding creates a **shortcut** for the model: instead of learning the hard task (biology), it learns the easy task (subgroup membership).\n",
    "\n",
    "### The Shortcut Learning Problem\n",
    "\n",
    "Consider two tasks:\n",
    "\n",
    "**Task 1 (Hard)**: Learn biology\n",
    "```\n",
    "Input:  Gene expression (10,000 genes)\n",
    "Goal:   Predict cancer vs. healthy\n",
    "Signal: Subtle, distributed across multiple pathways\n",
    "        Requires integration of information\n",
    "        Noisy, overlapping distributions\n",
    "```\n",
    "\n",
    "**Task 2 (Easy)**: Learn site membership\n",
    "```\n",
    "Input:  Same gene expression data\n",
    "Goal:   Predict site membership (A, B, or C)\n",
    "Signal: Strong, consistent within-site patterns\n",
    "        Technical artifacts affect ALL features simultaneously\n",
    "        Clean separation in PCA/t-SNE\n",
    "```\n",
    "\n",
    "**If site membership predicts disease** â†’ Model defaults to Task 2 because it's easier and gives better training performance!\n",
    "\n",
    "## Perfect vs. Partial Confounding\n",
    "\n",
    "### Perfect Confounding\n",
    "```\n",
    "Site A: 100% healthy (n=50)\n",
    "Site B: 100% cancer  (n=50)\n",
    "```\n",
    "\n",
    "**Consequences**:\n",
    "- Site membership **deterministically predicts** outcome\n",
    "- Model can achieve **100% accuracy** without using any biology\n",
    "- **Impossible to disentangle** site effects from disease effects\n",
    "- Random CV gives **wildly optimistic** performance estimates\n",
    "\n",
    "**Feature selection behavior**:\n",
    "- Selectors pick features that differ between sites (technical artifacts)\n",
    "- True biological features may be ignored if site effects are stronger\n",
    "\n",
    "### Partial Confounding\n",
    "```\n",
    "Site A: 70% healthy, 30% cancer  (n=50)\n",
    "Site B: 30% healthy, 70% cancer  (n=50)\n",
    "```\n",
    "\n",
    "**Consequences**:\n",
    "- Site membership is **informative but not deterministic**\n",
    "- Model learns a **mixture of site effects + biology**\n",
    "- **Difficult to assess**: Which features are causal?\n",
    "- Performance degrades gracefully on new sites (not catastrophic failure)\n",
    "\n",
    "**Feature selection behavior**:\n",
    "- Selectors pick a mix of technical artifacts and true biology\n",
    "- Relative importance depends on effect sizes\n",
    "- Instability increases: different CV folds may emphasize different features\n",
    "\n",
    "## Mathematical Perspective\n",
    "\n",
    "Let's formalize this:\n",
    "\n",
    "**Observed data**: X (features), Y (disease status), S (site membership)\n",
    "\n",
    "**Ideal scenario (no confounding)**:\n",
    "```\n",
    "P(Y|S) = P(Y)          Site doesn't predict disease\n",
    "P(X|S) â‰  P(X)          But site affects measurements\n",
    "Model learns: P(Y|X)   Uses biology, ignores site\n",
    "```\n",
    "\n",
    "**Confounded scenario**:\n",
    "```\n",
    "P(Y|S) â‰  P(Y)          Site predicts disease!\n",
    "P(X|S) â‰  P(X)          Site affects measurements\n",
    "Model learns: P(Y|S)   Uses site, ignores biology\n",
    "```\n",
    "\n",
    "**The model's perspective**:\n",
    "- It seeks the path of least resistance (maximum likelihood)\n",
    "- If P(Y|S) is easier to learn than P(Y|X_biology), it will learn site markers\n",
    "- The model doesn't \"know\" which features are causal â€“ it just optimizes the objective function\n",
    "\n",
    "## Visualization: Decision Boundaries\n",
    "\n",
    "```\n",
    "Feature Space (2D simplified view)\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "Scenario A: No confounding\n",
    "           Feature 2\n",
    "              â†‘\n",
    "    Site A    |    Site B\n",
    "    ğŸ”µ  ğŸ”´    |    ğŸ”µ  ğŸ”´     \n",
    "    ğŸ”µ  ğŸ”´    |    ğŸ”µ  ğŸ”´\n",
    "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€|â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Feature 1\n",
    "    ğŸ”´  ğŸ”µ    |    ğŸ”´  ğŸ”µ\n",
    "    ğŸ”´  ğŸ”µ    |    ğŸ”´  ğŸ”µ\n",
    "              |\n",
    "\n",
    "Decision boundary (biology): â”€ â”€ â”€ â”€ (horizontal)\n",
    "Decision boundary (site):    â”‚         (vertical)\n",
    "\n",
    "â†’ Model must use Feature 2 (biology) to classify\n",
    "â†’ Feature 1 (site marker) is uninformative\n",
    "\n",
    "\n",
    "Scenario B: Perfect confounding\n",
    "           Feature 2\n",
    "              â†‘\n",
    "    Site A    |    Site B\n",
    "    ğŸ”µ  ğŸ”µ    |    ğŸ”´  ğŸ”´     \n",
    "    ğŸ”µ  ğŸ”µ    |    ğŸ”´  ğŸ”´\n",
    "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€|â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Feature 1\n",
    "    ğŸ”µ  ğŸ”µ    |    ğŸ”´  ğŸ”´\n",
    "    ğŸ”µ  ğŸ”µ    |    ğŸ”´  ğŸ”´\n",
    "              |\n",
    "\n",
    "Decision boundary (biology): â”€ â”€ â”€ â”€ (could be anywhere)\n",
    "Decision boundary (site):    â”‚         (vertical)\n",
    "\n",
    "â†’ Model learns site boundary (perfect separation!)\n",
    "â†’ Biological signal is invisible/irrelevant\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Question 3\n",
    "\n",
    "**Scenario**: You train a cancer classifier on a multi-site dataset with partial confounding:\n",
    "- Your model achieves 85% AUC with random 5-fold CV\n",
    "- When you apply it to a completely new site, performance drops to 55% AUC (barely better than random)\n",
    "\n",
    "**Questions**:\n",
    "1. What does this performance gap tell you about what your model learned?\n",
    "2. Why did random CV fail to detect this problem?\n",
    "3. If you had to estimate the \"true\" biological signal strength, would you trust the 85% or 55% estimate?\n",
    "\n",
    "<details>\n",
    "<summary>Click to see answer</summary>\n",
    "\n",
    "**Answer 1**: The model learned **mostly site-specific artifacts**, not generalizable biology:\n",
    "- The 85% AUC included ~30% from biology and ~55% from memorizing site patterns\n",
    "- At a new site, site-specific features are completely unhelpful\n",
    "- The remaining 55% AUC represents a mix of biology (signal) and lucky noise\n",
    "\n",
    "**Answer 2**: Random CV failed because:\n",
    "- Each training fold contained samples from **all sites**\n",
    "- Each test fold also contained samples from **the same sites**\n",
    "- The model could use site markers in training **and** test\n",
    "- This mimics the training distribution but not real-world deployment (new sites)\n",
    "\n",
    "**Answer 3**: **Neither estimate is trustworthy**:\n",
    "- 85% is **too optimistic**: Inflated by site artifacts\n",
    "- 55% is **too pessimistic**: Includes uncertainty from distributional shift (new site has different data distribution)\n",
    "\n",
    "Better approach:\n",
    "- Use **leave-one-site-out CV**: Train on sites A+B, test on site C (rotate)\n",
    "- Average performance across held-out sites: e.g., 68% AUC\n",
    "- This 68% better reflects generalizable biology\n",
    "- The gap (85% - 68% = 17%) quantifies site-specific overfitting\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Why Standard Cross-Validation Fails\n",
    "\n",
    "## The Random CV Trap\n",
    "\n",
    "Standard k-fold cross-validation randomly splits samples into training and test sets. This seems reasonable, but it **breaks down completely** under confounding.\n",
    "\n",
    "### Example: Perfect Confounding\n",
    "\n",
    "```\n",
    "Dataset:\n",
    "Site A: 50 healthy samples\n",
    "Site B: 50 cancer samples\n",
    "```\n",
    "\n",
    "**Random 5-fold CV**:\n",
    "```\n",
    "Fold 1:\n",
    "  Train: 40 from Site A (healthy) + 40 from Site B (cancer)\n",
    "  Test:  10 from Site A (healthy) + 10 from Site B (cancer)\n",
    "  \n",
    "Model learns: \"If feature X (site marker) is high â†’ predict cancer\"\n",
    "Test performance: 100% accuracy!\n",
    "```\n",
    "\n",
    "**What went wrong?**\n",
    "- Test set contains samples from **the same sites as training**\n",
    "- Site markers work perfectly in both train and test\n",
    "- CV reports 100% accuracy, suggesting perfect biology\n",
    "- Reality: Model memorized technical artifacts\n",
    "\n",
    "**Deployment to new Site C**:\n",
    "```\n",
    "Site C has different instruments, protocols, patient demographics\n",
    "â†’ Site markers from A/B are irrelevant\n",
    "â†’ Model performance: ~50% (random guessing)\n",
    "```\n",
    "\n",
    "## The Group CV Solution\n",
    "\n",
    "**Principle**: Test and training sets must come from **different groups** (sites, batches).\n",
    "\n",
    "### Leave-One-Site-Out CV (LOSO-CV)\n",
    "\n",
    "```\n",
    "Dataset:\n",
    "Site A: 33 samples (17 healthy, 16 cancer)\n",
    "Site B: 34 samples (16 healthy, 18 cancer)  \n",
    "Site C: 33 samples (17 healthy, 16 cancer)\n",
    "```\n",
    "\n",
    "**LOSO-CV**:\n",
    "```\n",
    "Fold 1:\n",
    "  Train: Sites A + B (67 samples)\n",
    "  Test:  Site C (33 samples)\n",
    "\n",
    "Fold 2:\n",
    "  Train: Sites A + C (66 samples)\n",
    "  Test:  Site B (34 samples)\n",
    "\n",
    "Fold 3:\n",
    "  Train: Sites B + C (67 samples)\n",
    "  Test:  Site A (33 samples)\n",
    "```\n",
    "\n",
    "**Why it works**:\n",
    "- Each test site is **completely unseen** during training\n",
    "- Site-specific features are useless for prediction\n",
    "- Only generalizable biology contributes to performance\n",
    "- Mimics real-world deployment (new site/cohort)\n",
    "\n",
    "**Trade-offs**:\n",
    "- âœ… Honest estimate of generalization\n",
    "- âœ… Forces model to learn robust features\n",
    "- âŒ Requires multiple sites/batches (minimum 3)\n",
    "- âŒ Smaller training sets per fold\n",
    "- âŒ Higher variance in performance estimates\n",
    "\n",
    "## Visual Comparison\n",
    "\n",
    "```\n",
    "Random CV (wrong for confounded data)\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Fold 1: [A A A B B | A B B C C]  â† Test has samples from all sites\n",
    "Fold 2: [A A B B C | A A B C C]\n",
    "Fold 3: [A B B C C | A A A B C]\n",
    "\n",
    "â†’ Model can use site markers\n",
    "â†’ Optimistic performance\n",
    "\n",
    "\n",
    "Group CV (correct for confounded data)\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Fold 1: [B B B B C C C C | A A A A]  â† Test is entire site\n",
    "Fold 2: [A A A A C C C C | B B B B]\n",
    "Fold 3: [A A A A B B B B | C C C C]\n",
    "\n",
    "â†’ Model cannot use site markers\n",
    "â†’ Realistic performance\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Question 4\n",
    "\n",
    "**Scenario**: You're designing a benchmark to test feature selection methods under batch effects.\n",
    "\n",
    "You generate synthetic data:\n",
    "- 100 samples (50 healthy, 50 disease)\n",
    "- 10 informative features (true biology)\n",
    "- 490 noise features\n",
    "- 5 batches with strong batch effects but **balanced class distribution** in each batch\n",
    "\n",
    "**Questions**:\n",
    "1. Is this dataset confounded? Why or why not?\n",
    "2. Would you expect random CV and batch-aware CV to give similar or different performance estimates?\n",
    "3. Which CV strategy would better test feature selection stability?\n",
    "\n",
    "<details>\n",
    "<summary>Click to see answer</summary>\n",
    "\n",
    "**Answer 1**: **No, this is not confounded** because class distribution is balanced across batches:\n",
    "```\n",
    "Batch 1: 10 healthy, 10 disease\n",
    "Batch 2: 10 healthy, 10 disease\n",
    "...\n",
    "Batch membership does not predict outcome\n",
    "```\n",
    "\n",
    "**Answer 2**: **Similar performance**, but for different reasons:\n",
    "\n",
    "*Random CV*:\n",
    "- Model sees all batches in training and test\n",
    "- Can learn to ignore batch effects or adjust for them\n",
    "- Biology + batch correction â†’ good performance\n",
    "\n",
    "*Batch-aware CV*:\n",
    "- Model trained on some batches, tested on others\n",
    "- Must learn batch-invariant features (pure biology)\n",
    "- Biology only â†’ good performance (if strong signal)\n",
    "\n",
    "**Answer 3**: **Batch-aware CV is better for stability testing**:\n",
    "- Exposes whether selected features generalize across batches\n",
    "- If a feature selector picks batch-specific noise features, batch-aware CV will show poor performance\n",
    "- Random CV might hide this problem if the model can \"memorize\" batch patterns\n",
    "\n",
    "**Key insight**: Even without confounding, non-causal variation poses a **generalization challenge**. Group CV tests the harder (and more realistic) generalization scenario.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Real-World Consequences\n",
    "\n",
    "## Why This Matters for Biomedical Research\n",
    "\n",
    "Non-causal variation and confounding aren't just theoretical concerns. They are responsible for many high-profile failures in biomedical machine learning.\n",
    "\n",
    "### The Replication Crisis\n",
    "\n",
    "**Published biomarker signatures that failed to replicate**:\n",
    "\n",
    "1. **Cancer prognostic signatures** (early 2000s)\n",
    "   - Multiple gene expression signatures published with 70-90% accuracy\n",
    "   - Failed validation in independent cohorts (AUC dropped to 50-60%)\n",
    "   - Post-hoc analysis: Signatures captured **batch effects** and **platform differences**\n",
    "\n",
    "2. **COVID-19 diagnostic models** (2020-2021)\n",
    "   - Hundreds of chest X-ray deep learning models published\n",
    "   - Most learned to detect **image source** (hospital, scanner model) not COVID\n",
    "   - Models worked perfectly on training hospital data, failed elsewhere\n",
    "\n",
    "3. **Psychiatric disorder classification** (ongoing)\n",
    "   - Brain imaging studies with 80-95% accuracy in single-site studies\n",
    "   - Drop to 50-65% in multi-site validation\n",
    "   - Site effects (scanner manufacturer, acquisition protocol) dominate biology\n",
    "\n",
    "### Why Models Fail in Clinical Practice\n",
    "\n",
    "Even when a model has \"good\" cross-validation performance, deployment fails because:\n",
    "\n",
    "```\n",
    "Training environment:\n",
    "- Single hospital or consortium\n",
    "- Consistent protocols\n",
    "- Specific patient population\n",
    "- Known equipment\n",
    "\n",
    "â†’ Model learns: Biology + Local artifacts\n",
    "\n",
    "Deployment environment:\n",
    "- Different hospital\n",
    "- Different protocols  \n",
    "- Different population demographics\n",
    "- Different equipment\n",
    "\n",
    "â†’ Local artifacts are completely different\n",
    "â†’ Model performance collapses\n",
    "```\n",
    "\n",
    "### Economic and Scientific Costs\n",
    "\n",
    "**Failed clinical trials**:\n",
    "- Millions spent validating biomarkers that don't generalize\n",
    "- Patients enrolled in studies based on false predictions\n",
    "- Opportunity cost: Better approaches not tested\n",
    "\n",
    "**Wasted research effort**:\n",
    "- Years spent developing models that memorize artifacts\n",
    "- Follow-up studies chase spurious associations\n",
    "- Incorrect biological hypotheses published and cited\n",
    "\n",
    "**Loss of trust**:\n",
    "- Clinicians skeptical of ML/AI after high-profile failures\n",
    "- Funding agencies hesitant to support ML-heavy proposals\n",
    "- Patients harmed by overconfident predictions\n",
    "\n",
    "## The Pedagogical Value of Synthetic Confounding\n",
    "\n",
    "**Why we need synthetic data with controlled confounding**:\n",
    "\n",
    "### 1. Ground truth knowledge\n",
    "- We **know** which features are causal (informative) vs. artifacts\n",
    "- Can quantify: \"Model used 30% biology, 70% batch markers\"\n",
    "- Impossible with real data where truth is unknown\n",
    "\n",
    "### 2. Systematic testing\n",
    "```\n",
    "Vary confounding strength:\n",
    "- No confounding (balanced design)\n",
    "- Weak (60/40 class split per site)\n",
    "- Moderate (70/30 split)\n",
    "- Strong (90/10 split)  \n",
    "- Perfect (100/0 split)\n",
    "\n",
    "â†’ Observe model degradation curve\n",
    "â†’ Identify which methods are robust\n",
    "```\n",
    "\n",
    "### 3. Safe learning environment\n",
    "- Students make mistakes **before** working with real patient data\n",
    "- Learn to spot warning signs of confounding\n",
    "- Build intuition for evaluation strategies\n",
    "\n",
    "### 4. Method comparison\n",
    "- Benchmark feature selection methods under identical confounding\n",
    "- Test correction strategies (ComBat, batch normalization)\n",
    "- Validate CV strategies (random vs. group CV)\n",
    "\n",
    "### 5. Reproducibility\n",
    "- Deterministic seed â†’ exactly reproducible experiments\n",
    "- Others can verify claims about \"confounding-robust method\"\n",
    "- Easier peer review and teaching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Reflection Question\n",
    "\n",
    "**Scenario**: You're reviewing a paper that claims a 10-gene signature predicts Alzheimer's disease with 92% accuracy.\n",
    "\n",
    "The paper reports:\n",
    "- Training data: 500 samples from 5 memory clinics\n",
    "- Validation: 10-fold cross-validation\n",
    "- Results: AUC = 0.92, sensitivity = 88%, specificity = 89%\n",
    "\n",
    "**Questions**:\n",
    "1. What critical information is missing from this description?\n",
    "2. List at least three potential sources of confounding that could inflate these results.\n",
    "3. What evaluation strategy would you recommend to test generalization?\n",
    "4. If you could ask for one additional experiment, what would it be?\n",
    "\n",
    "<details>\n",
    "<summary>Click to see answer</summary>\n",
    "\n",
    "**Answer 1 - Critical missing information**:\n",
    "- **Class distribution per clinic**: Are some clinics mostly controls while others are mostly cases?\n",
    "- **CV strategy**: Was it random 10-fold or leave-one-clinic-out?\n",
    "- **Clinic characteristics**: Specialized memory clinics vs. general neurology?\n",
    "- **When samples collected**: All at once or over years?\n",
    "- **Measurement protocol**: Same for all clinics or heterogeneous?\n",
    "- **Feature selection**: Done before CV (leakage) or within CV?\n",
    "- **Population demographics**: Age, sex,... distribution per clinic?\n",
    "\n",
    "**Answer 2 - Potential confounding sources**:\n",
    "1. **Disease severity confounding**: \n",
    "   - Specialized memory clinics recruit late-stage Alzheimer's\n",
    "   - General clinics recruit early-stage + controls\n",
    "   - Model learns clinic markers â†’ predicts disease stage, not disease presence\n",
    "\n",
    "2. **Technical confounding**:\n",
    "   - Different RNA extraction protocols per clinic\n",
    "   - Different storage times (older samples degrade differently)\n",
    "   - Different processing batches per clinic\n",
    "\n",
    "3. **Population confounding**:\n",
    "   - Clinic 1 in Scandinavia (high APOE Îµ4 frequency)\n",
    "   - Clinic 2 in Asia (lower APOE Îµ4 frequency)\n",
    "   - Geographic genetics correlate with both clinic and disease risk\n",
    "\n",
    "4. **Recruitment bias**:\n",
    "   - Early years: mostly controls (study establishment)\n",
    "   - Later years: mostly cases (focused recruitment)\n",
    "   - Sample age correlates with disease prevalence\n",
    "\n",
    "**Answer 3 - Recommended evaluation**:\n",
    "- **Leave-one-clinic-out CV**: \n",
    "  - Train on 4 clinics, test on 5th\n",
    "  - Repeat for all 5 clinics\n",
    "  - Report mean and range of AUC\n",
    "- **Expected outcome**: If confounded, AUC drops to 0.65-0.75\n",
    "- **If AUC remains >0.85**: Suggests robust biological signal\n",
    "\n",
    "**Answer 4 - Additional experiment**:\n",
    "**External validation on completely independent cohort**:\n",
    "- New data from different country/healthcare system\n",
    "- Different measurement platform (e.g., RNA-seq if original was microarray)\n",
    "- Prospective collection (not retrospective)\n",
    "- Pre-register analysis plan to prevent cherry-picking\n",
    "\n",
    "**Red flags if authors refuse**:\n",
    "- \"External validation is too expensive\"\n",
    "- \"Our signature only works with this specific protocol\"\n",
    "- \"Other cohorts have different patient characteristics\"\n",
    "\n",
    "These are often signs the model learned dataset-specific artifacts, not biology.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "### 1. Non-causal variation is ubiquitous in biomedical data\n",
    "- **Batch effects**: Sample processing groups\n",
    "- **Site effects**: Multi-center studies\n",
    "- **Instrument effects**: Technology differences\n",
    "- **Time effects**: Recruitment period, sample age\n",
    "\n",
    "### 2. Confounding occurs when non-causal factors predict the outcome\n",
    "- **Perfect confounding**: Complete overlap (e.g., Site A = 100% healthy)\n",
    "- **Partial confounding**: Strong association (e.g., Site A = 80% healthy)\n",
    "- **Distributional shift**: Different non-causal patterns in deployment\n",
    "\n",
    "### 3. Models preferentially learn shortcuts over biology\n",
    "- Technical artifacts often have **stronger signals** than biology\n",
    "- Models optimize training objective, not causal understanding\n",
    "- \"Good\" training performance can hide complete failure to learn biology\n",
    "\n",
    "### 4. Random CV fails catastrophically under confounding\n",
    "- Test set contains same sites/batches as training\n",
    "- Gives **wildly optimistic** performance estimates\n",
    "- Does not reflect real-world deployment scenarios\n",
    "\n",
    "### 5. Group CV is essential for honest evaluation\n",
    "- Leave-one-site-out, leave-one-batch-out\n",
    "- Forces models to learn generalizable features\n",
    "- Mimics true deployment (new site, new cohort)\n",
    "\n",
    "### 6. Synthetic data enables systematic study\n",
    "- Control confounding strength\n",
    "- Know ground truth (causal vs. artifact features)\n",
    "- Test methods under reproducible conditions\n",
    "- Learn to recognize and avoid pitfalls\n",
    "\n",
    "## What You've Learned\n",
    "\n",
    "You should now be able to:\n",
    "- Distinguish causal biological variation from technical artifacts\n",
    "- Identify common sources of non-causal variation in study designs\n",
    "- Explain why confounding is dangerous for ML models\n",
    "- Recognize when random CV is inappropriate\n",
    "- Articulate why group-aware CV is necessary\n",
    "- Understand the value of synthetic confounded data for method testing\n",
    "\n",
    "## Looking Ahead\n",
    "\n",
    "In the next notebooks, you will:\n",
    "\n",
    "**Lesson 4b: Generating Non-Causal Variation**\n",
    "- Use `biomedical-data-generator` to add batch/site effects\n",
    "- Create perfect and partial confounding scenarios\n",
    "- Visualize confounding in PCA and t-SNE\n",
    "- Control effect size of artifacts vs. biology\n",
    "\n",
    "**Lesson 4c: Evaluation Pitfalls**\n",
    "- Compare random CV vs. group CV empirically\n",
    "- Measure performance degradation under confounding\n",
    "- Implement proper nested CV with grouping\n",
    "- Detect leakage from feature selection\n",
    "\n",
    "**Lesson 4d: Method Testing**\n",
    "- Benchmark feature selection stability under confounding\n",
    "- Test batch correction methods (e.g., ComBat)\n",
    "- Compare model robustness to distributional shift\n",
    "- Design your own confounding robustness benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "â¡ï¸ **Continue with: [Lesson 4b: Generating Non-Causal Variation](04b_non_causal_variation_generating.ipynb)**\n",
    "\n",
    "In Lesson 4b, you will:\n",
    "- Learn to add batch and site effects to synthetic data using `biomedical-data-generator`\n",
    "- Create datasets with different confounding strengths\n",
    "- Visualize how non-causal variation affects feature space\n",
    "- Prepare data for evaluation experiments in Lesson 4c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
